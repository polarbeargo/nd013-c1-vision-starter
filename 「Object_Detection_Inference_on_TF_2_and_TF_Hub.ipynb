{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/polarbeargo/nd013-c1-vision-starter/blob/main/%E3%80%8CObject_Detection_Inference_on_TF_2_and_TF_Hub.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "98rds-2OU-Rd"
      },
      "source": [
        "##### Copyright 2020 The TensorFlow Hub Authors.\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\");"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "1c95xMGcU5_Z"
      },
      "outputs": [],
      "source": [
        "#@title Copyright 2020 The TensorFlow Hub Authors. All Rights Reserved.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "# =============================================================================="
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V1UUX8SUUiMO"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://www.tensorflow.org/hub/tutorials/tf2_object_detection\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" />View on TensorFlow.org</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/hub/blob/master/examples/colab/tf2_object_detection.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/tensorflow/hub/blob/master/examples/colab/tf2_object_detection.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View on GitHub</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a href=\"https://storage.googleapis.com/tensorflow_docs/hub/examples/colab/tf2_object_detection.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" />Download notebook</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a href=\"https://tfhub.dev/tensorflow/collections/object_detection/1\"><img src=\"https://www.tensorflow.org/images/hub_logo_32px.png\" />See TF Hub models</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rOvvWAVTkMR7"
      },
      "source": [
        "# TensorFlow Hub Object Detection Colab\n",
        "\n",
        "Welcome to the TensorFlow Hub Object Detection Colab! This notebook will take you through the steps of running an \"out-of-the-box\" object detection model on images."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IRImnk_7WOq1"
      },
      "source": [
        "### More models\n",
        "[This](https://tfhub.dev/tensorflow/collections/object_detection/1) collection contains TF2 object detection models that have been trained on the COCO 2017 dataset. [Here](https://tfhub.dev/s?module-type=image-object-detection) you can find all object detection models that are currently hosted on [tfhub.dev](https://tfhub.dev/)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vPs64QA1Zdov"
      },
      "source": [
        "## Imports and Setup\n",
        "\n",
        "Let's start with the base imports."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iPz7O29pX942",
        "outputId": "e5e00fac-711a-40b1-be52-baa1761499a7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir('/content/gdrive/My Drive/home/workspace') \n",
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "asPugmNWYR2o",
        "outputId": "91bbb19a-316a-4d5c-ace2-13e4576dca7b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " create_splits.py\t\t    label_map.pbtxt\n",
            " data\t\t\t\t    LICENSE.md\n",
            " download_process.py\t\t    models\n",
            " edit_config.py\t\t\t    pipeline.config\n",
            " experiments\t\t\t    __pycache__\n",
            "'Exploratory Data Analysis.ipynb'   README.md\n",
            "'Explore augmentations.ipynb'\t    training\n",
            " filenames.txt\t\t\t    utils.py\n",
            " inference_video.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xk4FU-jx9kc3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7df3defe-5f7b-4a92-c706-4ba3227909bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow==2.4.1\n",
            "  Downloading tensorflow-2.4.1-cp37-cp37m-manylinux2010_x86_64.whl (394.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 394.3 MB 14 kB/s \n",
            "\u001b[?25hCollecting tensorflow-estimator<2.5.0,>=2.4.0\n",
            "  Downloading tensorflow_estimator-2.4.0-py2.py3-none-any.whl (462 kB)\n",
            "\u001b[K     |████████████████████████████████| 462 kB 51.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (1.1.2)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (3.3.0)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (1.6.3)\n",
            "Requirement already satisfied: numpy~=1.19.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (1.19.5)\n",
            "Collecting wrapt~=1.12.1\n",
            "  Downloading wrapt-1.12.1.tar.gz (27 kB)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (3.17.3)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (1.1.0)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (0.37.0)\n",
            "Collecting grpcio~=1.32.0\n",
            "  Downloading grpcio-1.32.0-cp37-cp37m-manylinux2014_x86_64.whl (3.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8 MB 33.8 MB/s \n",
            "\u001b[?25hCollecting typing-extensions~=3.7.4\n",
            "  Downloading typing_extensions-3.7.4.3-py3-none-any.whl (22 kB)\n",
            "Collecting gast==0.3.3\n",
            "  Downloading gast-0.3.3-py2.py3-none-any.whl (9.7 kB)\n",
            "Collecting flatbuffers~=1.12.0\n",
            "  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: tensorboard~=2.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (2.7.0)\n",
            "Collecting h5py~=2.10.0\n",
            "  Downloading h5py-2.10.0-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9 MB 19.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (0.12.0)\n",
            "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (1.15.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.1) (0.6.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.1) (1.35.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.1) (1.0.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.1) (0.4.6)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.1) (3.3.6)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.1) (57.4.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.1) (2.23.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.1) (1.8.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.1) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.1) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.1) (4.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow==2.4.1) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow==2.4.1) (4.8.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.4->tensorflow==2.4.1) (3.6.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.1) (0.4.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.1) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.1) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.1) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.1) (2.10)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow==2.4.1) (3.1.1)\n",
            "Building wheels for collected packages: wrapt\n",
            "  Building wheel for wrapt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wrapt: filename=wrapt-1.12.1-cp37-cp37m-linux_x86_64.whl size=68723 sha256=55b5cacaf4e1003d6f25df251d8a2687f0064be6cb3a286cefb75c6892017feb\n",
            "  Stored in directory: /root/.cache/pip/wheels/62/76/4c/aa25851149f3f6d9785f6c869387ad82b3fd37582fa8147ac6\n",
            "Successfully built wrapt\n",
            "Installing collected packages: typing-extensions, grpcio, wrapt, tensorflow-estimator, h5py, gast, flatbuffers, tensorflow\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing-extensions 3.10.0.2\n",
            "    Uninstalling typing-extensions-3.10.0.2:\n",
            "      Successfully uninstalled typing-extensions-3.10.0.2\n",
            "  Attempting uninstall: grpcio\n",
            "    Found existing installation: grpcio 1.42.0\n",
            "    Uninstalling grpcio-1.42.0:\n",
            "      Successfully uninstalled grpcio-1.42.0\n",
            "  Attempting uninstall: wrapt\n",
            "    Found existing installation: wrapt 1.13.3\n",
            "    Uninstalling wrapt-1.13.3:\n",
            "      Successfully uninstalled wrapt-1.13.3\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.7.0\n",
            "    Uninstalling tensorflow-estimator-2.7.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.7.0\n",
            "  Attempting uninstall: h5py\n",
            "    Found existing installation: h5py 3.1.0\n",
            "    Uninstalling h5py-3.1.0:\n",
            "      Successfully uninstalled h5py-3.1.0\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.4.0\n",
            "    Uninstalling gast-0.4.0:\n",
            "      Successfully uninstalled gast-0.4.0\n",
            "  Attempting uninstall: flatbuffers\n",
            "    Found existing installation: flatbuffers 2.0\n",
            "    Uninstalling flatbuffers-2.0:\n",
            "      Successfully uninstalled flatbuffers-2.0\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.7.0\n",
            "    Uninstalling tensorflow-2.7.0:\n",
            "      Successfully uninstalled tensorflow-2.7.0\n",
            "Successfully installed flatbuffers-1.12 gast-0.3.3 grpcio-1.32.0 h5py-2.10.0 tensorflow-2.4.1 tensorflow-estimator-2.4.0 typing-extensions-3.7.4.3 wrapt-1.12.1\n"
          ]
        }
      ],
      "source": [
        "# This Colab requires TF 2.5.\n",
        "!pip install -U \"tensorflow == 2.4.1\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xxde7khZbfAY",
        "outputId": "9953c6cc-fb17-4fa1-bf5e-b42c3ccbea71"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/My Drive/home/workspace\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip show tensorflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1jtgBtNZpofl",
        "outputId": "e9fd7c58-2049-4ef2-fc5e-9063cf6d18f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: tensorflow\n",
            "Version: 2.7.0\n",
            "Summary: TensorFlow is an open source machine learning framework for everyone.\n",
            "Home-page: https://www.tensorflow.org/\n",
            "Author: Google Inc.\n",
            "Author-email: packages@tensorflow.org\n",
            "License: Apache 2.0\n",
            "Location: /usr/local/lib/python3.7/dist-packages\n",
            "Requires: grpcio, numpy, wrapt, astunparse, tensorflow-estimator, tensorflow-io-gcs-filesystem, keras-preprocessing, keras, gast, tensorboard, h5py, wheel, google-pasta, absl-py, protobuf, typing-extensions, six, opt-einsum, flatbuffers, libclang, termcolor\n",
            "Required-by: tf-models-official, tensorflow-text, kapre\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ieP8XupO5VUK",
        "outputId": "330a43b9-fa16-4958-ec5f-a0898a4b53cd"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/My Drive/home/workspace\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python edit_config.py --train_dir ./data/waymo/train/ --eval_dir ./data/waymo/val/ --batch_size 4 --checkpoint ./training/pretrained-models/ssd_resnet50_v1_fpn_640x640_coco17_tpu-8/checkpoint/ckpt-0 --label_map label_map.pbtxt"
      ],
      "metadata": {
        "id": "T5sS7UVk3sAx"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python experiments/model_main_tf2.py --model_dir=training/reference/ --pipeline_config_path=training/reference/pipeline_new.config "
      ],
      "metadata": {
        "id": "Lm312wp5WdeF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d11124e-828a-490a-daa8-a546b69b86fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2021-12-21 03:07:15.322044: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
            "I1221 03:07:15.326468 139859838478208 mirrored_strategy.py:376] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
            "INFO:tensorflow:Maybe overwriting train_steps: None\n",
            "I1221 03:07:15.335556 139859838478208 config_util.py:552] Maybe overwriting train_steps: None\n",
            "INFO:tensorflow:Maybe overwriting use_bfloat16: False\n",
            "I1221 03:07:15.335804 139859838478208 config_util.py:552] Maybe overwriting use_bfloat16: False\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/model_lib_v2.py:564: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "rename to distribute_datasets_from_function\n",
            "W1221 03:07:15.367074 139859838478208 deprecation.py:347] From /usr/local/lib/python3.7/dist-packages/object_detection/model_lib_v2.py:564: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "rename to distribute_datasets_from_function\n",
            "INFO:tensorflow:Reading unweighted datasets: ['./data/waymo/train/segment-10153695247769592104_787_000_807_000_with_camera_labels.tfrecord', './data/waymo/train/segment-1005081002024129653_5313_150_5333_150_with_camera_labels.tfrecord', './data/waymo/train/segment-10094743350625019937_3420_000_3440_000_with_camera_labels.tfrecord', './data/waymo/train/segment-10017090168044687777_6380_000_6400_000_with_camera_labels.tfrecord', './data/waymo/train/segment-10061305430875486848_1080_000_1100_000_with_camera_labels.tfrecord', './data/waymo/train/segment-1022527355599519580_4866_960_4886_960_with_camera_labels.tfrecord', './data/waymo/train/segment-10226164909075980558_180_000_200_000_with_camera_labels.tfrecord', './data/waymo/train/segment-10241508783381919015_2889_360_2909_360_with_camera_labels.tfrecord', './data/waymo/train/segment-10231929575853664160_1160_000_1180_000_with_camera_labels.tfrecord', './data/waymo/train/segment-10206293520369375008_2796_800_2816_800_with_camera_labels.tfrecord', './data/waymo/train/segment-10235335145367115211_5420_000_5440_000_with_camera_labels.tfrecord', './data/waymo/train/segment-10444454289801298640_4360_000_4380_000_with_camera_labels.tfrecord', './data/waymo/train/segment-10275144660749673822_5755_561_5775_561_with_camera_labels.tfrecord', './data/waymo/train/segment-10455472356147194054_1560_000_1580_000_with_camera_labels.tfrecord', './data/waymo/train/segment-10327752107000040525_1120_000_1140_000_with_camera_labels.tfrecord', './data/waymo/train/segment-10485926982439064520_4980_000_5000_000_with_camera_labels.tfrecord', './data/waymo/train/segment-10517728057304349900_3360_000_3380_000_with_camera_labels.tfrecord', './data/waymo/train/segment-10526338824408452410_5714_660_5734_660_with_camera_labels.tfrecord', './data/waymo/train/segment-10500357041547037089_1474_800_1494_800_with_camera_labels.tfrecord', './data/waymo/train/segment-10588771936253546636_2300_000_2320_000_with_camera_labels.tfrecord', './data/waymo/train/segment-10664823084372323928_4360_000_4380_000_with_camera_labels.tfrecord', './data/waymo/train/segment-10625026498155904401_200_000_220_000_with_camera_labels.tfrecord', './data/waymo/train/segment-10770759614217273359_1465_000_1485_000_with_camera_labels.tfrecord', './data/waymo/train/segment-10723911392655396041_860_000_880_000_with_camera_labels.tfrecord', './data/waymo/train/segment-10724020115992582208_7660_400_7680_400_with_camera_labels.tfrecord', './data/waymo/train/segment-10750135302241325253_180_000_200_000_with_camera_labels.tfrecord', './data/waymo/train/segment-10923963890428322967_1445_000_1465_000_with_camera_labels.tfrecord', './data/waymo/train/segment-10786629299947667143_3440_000_3460_000_with_camera_labels.tfrecord', './data/waymo/train/segment-10793018113277660068_2714_540_2734_540_with_camera_labels.tfrecord', './data/waymo/train/segment-1083056852838271990_4080_000_4100_000_with_camera_labels.tfrecord', './data/waymo/train/segment-10876852935525353526_1640_000_1660_000_with_camera_labels.tfrecord', './data/waymo/train/segment-10964956617027590844_1584_680_1604_680_with_camera_labels.tfrecord', './data/waymo/train/segment-11004685739714500220_2300_000_2320_000_with_camera_labels.tfrecord', './data/waymo/train/segment-11070802577416161387_740_000_760_000_with_camera_labels.tfrecord', './data/waymo/train/segment-11017034898130016754_697_830_717_830_with_camera_labels.tfrecord', './data/waymo/train/segment-11199484219241918646_2810_030_2830_030_with_camera_labels.tfrecord', './data/waymo/train/segment-11113047206980595400_2560_000_2580_000_with_camera_labels.tfrecord', './data/waymo/train/segment-11236550977973464715_3620_000_3640_000_with_camera_labels.tfrecord', './data/waymo/train/segment-11318901554551149504_520_000_540_000_with_camera_labels.tfrecord', './data/waymo/train/segment-11355519273066561009_5323_000_5343_000_with_camera_labels.tfrecord', './data/waymo/train/segment-11343624116265195592_5910_530_5930_530_with_camera_labels.tfrecord', './data/waymo/train/segment-11454085070345530663_1905_000_1925_000_with_camera_labels.tfrecord', './data/waymo/train/segment-11252086830380107152_1540_000_1560_000_with_camera_labels.tfrecord', './data/waymo/train/segment-11388947676680954806_5427_320_5447_320_with_camera_labels.tfrecord', './data/waymo/train/segment-11566385337103696871_5740_000_5760_000_with_camera_labels.tfrecord', './data/waymo/train/segment-11588853832866011756_2184_462_2204_462_with_camera_labels.tfrecord', './data/waymo/train/segment-1146261869236413282_1680_000_1700_000_with_camera_labels.tfrecord', './data/waymo/train/segment-11918003324473417938_1400_000_1420_000_with_camera_labels.tfrecord', './data/waymo/train/segment-1172406780360799916_1660_000_1680_000_with_camera_labels.tfrecord', './data/waymo/train/segment-11799592541704458019_9828_750_9848_750_with_camera_labels.tfrecord', './data/waymo/train/segment-11674150664140226235_680_000_700_000_with_camera_labels.tfrecord', './data/waymo/train/segment-11839652018869852123_2565_000_2585_000_with_camera_labels.tfrecord', './data/waymo/train/segment-11847506886204460250_1640_000_1660_000_with_camera_labels.tfrecord', './data/waymo/train/segment-11925224148023145510_1040_000_1060_000_with_camera_labels.tfrecord', './data/waymo/train/segment-11928449532664718059_1200_000_1220_000_with_camera_labels.tfrecord', './data/waymo/train/segment-11967272535264406807_580_000_600_000_with_camera_labels.tfrecord', './data/waymo/train/segment-12161824480686739258_1813_380_1833_380_with_camera_labels.tfrecord', './data/waymo/train/segment-12027892938363296829_4086_280_4106_280_with_camera_labels.tfrecord']\n",
            "I1221 03:07:15.379043 139859838478208 dataset_builder.py:163] Reading unweighted datasets: ['./data/waymo/train/segment-10153695247769592104_787_000_807_000_with_camera_labels.tfrecord', './data/waymo/train/segment-1005081002024129653_5313_150_5333_150_with_camera_labels.tfrecord', './data/waymo/train/segment-10094743350625019937_3420_000_3440_000_with_camera_labels.tfrecord', './data/waymo/train/segment-10017090168044687777_6380_000_6400_000_with_camera_labels.tfrecord', './data/waymo/train/segment-10061305430875486848_1080_000_1100_000_with_camera_labels.tfrecord', './data/waymo/train/segment-1022527355599519580_4866_960_4886_960_with_camera_labels.tfrecord', './data/waymo/train/segment-10226164909075980558_180_000_200_000_with_camera_labels.tfrecord', './data/waymo/train/segment-10241508783381919015_2889_360_2909_360_with_camera_labels.tfrecord', './data/waymo/train/segment-10231929575853664160_1160_000_1180_000_with_camera_labels.tfrecord', './data/waymo/train/segment-10206293520369375008_2796_800_2816_800_with_camera_labels.tfrecord', './data/waymo/train/segment-10235335145367115211_5420_000_5440_000_with_camera_labels.tfrecord', './data/waymo/train/segment-10444454289801298640_4360_000_4380_000_with_camera_labels.tfrecord', './data/waymo/train/segment-10275144660749673822_5755_561_5775_561_with_camera_labels.tfrecord', './data/waymo/train/segment-10455472356147194054_1560_000_1580_000_with_camera_labels.tfrecord', './data/waymo/train/segment-10327752107000040525_1120_000_1140_000_with_camera_labels.tfrecord', './data/waymo/train/segment-10485926982439064520_4980_000_5000_000_with_camera_labels.tfrecord', './data/waymo/train/segment-10517728057304349900_3360_000_3380_000_with_camera_labels.tfrecord', './data/waymo/train/segment-10526338824408452410_5714_660_5734_660_with_camera_labels.tfrecord', './data/waymo/train/segment-10500357041547037089_1474_800_1494_800_with_camera_labels.tfrecord', './data/waymo/train/segment-10588771936253546636_2300_000_2320_000_with_camera_labels.tfrecord', './data/waymo/train/segment-10664823084372323928_4360_000_4380_000_with_camera_labels.tfrecord', './data/waymo/train/segment-10625026498155904401_200_000_220_000_with_camera_labels.tfrecord', './data/waymo/train/segment-10770759614217273359_1465_000_1485_000_with_camera_labels.tfrecord', './data/waymo/train/segment-10723911392655396041_860_000_880_000_with_camera_labels.tfrecord', './data/waymo/train/segment-10724020115992582208_7660_400_7680_400_with_camera_labels.tfrecord', './data/waymo/train/segment-10750135302241325253_180_000_200_000_with_camera_labels.tfrecord', './data/waymo/train/segment-10923963890428322967_1445_000_1465_000_with_camera_labels.tfrecord', './data/waymo/train/segment-10786629299947667143_3440_000_3460_000_with_camera_labels.tfrecord', './data/waymo/train/segment-10793018113277660068_2714_540_2734_540_with_camera_labels.tfrecord', './data/waymo/train/segment-1083056852838271990_4080_000_4100_000_with_camera_labels.tfrecord', './data/waymo/train/segment-10876852935525353526_1640_000_1660_000_with_camera_labels.tfrecord', './data/waymo/train/segment-10964956617027590844_1584_680_1604_680_with_camera_labels.tfrecord', './data/waymo/train/segment-11004685739714500220_2300_000_2320_000_with_camera_labels.tfrecord', './data/waymo/train/segment-11070802577416161387_740_000_760_000_with_camera_labels.tfrecord', './data/waymo/train/segment-11017034898130016754_697_830_717_830_with_camera_labels.tfrecord', './data/waymo/train/segment-11199484219241918646_2810_030_2830_030_with_camera_labels.tfrecord', './data/waymo/train/segment-11113047206980595400_2560_000_2580_000_with_camera_labels.tfrecord', './data/waymo/train/segment-11236550977973464715_3620_000_3640_000_with_camera_labels.tfrecord', './data/waymo/train/segment-11318901554551149504_520_000_540_000_with_camera_labels.tfrecord', './data/waymo/train/segment-11355519273066561009_5323_000_5343_000_with_camera_labels.tfrecord', './data/waymo/train/segment-11343624116265195592_5910_530_5930_530_with_camera_labels.tfrecord', './data/waymo/train/segment-11454085070345530663_1905_000_1925_000_with_camera_labels.tfrecord', './data/waymo/train/segment-11252086830380107152_1540_000_1560_000_with_camera_labels.tfrecord', './data/waymo/train/segment-11388947676680954806_5427_320_5447_320_with_camera_labels.tfrecord', './data/waymo/train/segment-11566385337103696871_5740_000_5760_000_with_camera_labels.tfrecord', './data/waymo/train/segment-11588853832866011756_2184_462_2204_462_with_camera_labels.tfrecord', './data/waymo/train/segment-1146261869236413282_1680_000_1700_000_with_camera_labels.tfrecord', './data/waymo/train/segment-11918003324473417938_1400_000_1420_000_with_camera_labels.tfrecord', './data/waymo/train/segment-1172406780360799916_1660_000_1680_000_with_camera_labels.tfrecord', './data/waymo/train/segment-11799592541704458019_9828_750_9848_750_with_camera_labels.tfrecord', './data/waymo/train/segment-11674150664140226235_680_000_700_000_with_camera_labels.tfrecord', './data/waymo/train/segment-11839652018869852123_2565_000_2585_000_with_camera_labels.tfrecord', './data/waymo/train/segment-11847506886204460250_1640_000_1660_000_with_camera_labels.tfrecord', './data/waymo/train/segment-11925224148023145510_1040_000_1060_000_with_camera_labels.tfrecord', './data/waymo/train/segment-11928449532664718059_1200_000_1220_000_with_camera_labels.tfrecord', './data/waymo/train/segment-11967272535264406807_580_000_600_000_with_camera_labels.tfrecord', './data/waymo/train/segment-12161824480686739258_1813_380_1833_380_with_camera_labels.tfrecord', './data/waymo/train/segment-12027892938363296829_4086_280_4106_280_with_camera_labels.tfrecord']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['./data/waymo/train/segment-10153695247769592104_787_000_807_000_with_camera_labels.tfrecord', './data/waymo/train/segment-1005081002024129653_5313_150_5333_150_with_camera_labels.tfrecord', './data/waymo/train/segment-10094743350625019937_3420_000_3440_000_with_camera_labels.tfrecord', './data/waymo/train/segment-10017090168044687777_6380_000_6400_000_with_camera_labels.tfrecord', './data/waymo/train/segment-10061305430875486848_1080_000_1100_000_with_camera_labels.tfrecord', './data/waymo/train/segment-1022527355599519580_4866_960_4886_960_with_camera_labels.tfrecord', './data/waymo/train/segment-10226164909075980558_180_000_200_000_with_camera_labels.tfrecord', './data/waymo/train/segment-10241508783381919015_2889_360_2909_360_with_camera_labels.tfrecord', './data/waymo/train/segment-10231929575853664160_1160_000_1180_000_with_camera_labels.tfrecord', './data/waymo/train/segment-10206293520369375008_2796_800_2816_800_with_camera_labels.tfrecord', './data/waymo/train/segment-10235335145367115211_5420_000_5440_000_with_camera_labels.tfrecord', './data/waymo/train/segment-10444454289801298640_4360_000_4380_000_with_camera_labels.tfrecord', './data/waymo/train/segment-10275144660749673822_5755_561_5775_561_with_camera_labels.tfrecord', './data/waymo/train/segment-10455472356147194054_1560_000_1580_000_with_camera_labels.tfrecord', './data/waymo/train/segment-10327752107000040525_1120_000_1140_000_with_camera_labels.tfrecord', './data/waymo/train/segment-10485926982439064520_4980_000_5000_000_with_camera_labels.tfrecord', './data/waymo/train/segment-10517728057304349900_3360_000_3380_000_with_camera_labels.tfrecord', './data/waymo/train/segment-10526338824408452410_5714_660_5734_660_with_camera_labels.tfrecord', './data/waymo/train/segment-10500357041547037089_1474_800_1494_800_with_camera_labels.tfrecord', './data/waymo/train/segment-10588771936253546636_2300_000_2320_000_with_camera_labels.tfrecord', './data/waymo/train/segment-10664823084372323928_4360_000_4380_000_with_camera_labels.tfrecord', './data/waymo/train/segment-10625026498155904401_200_000_220_000_with_camera_labels.tfrecord', './data/waymo/train/segment-10770759614217273359_1465_000_1485_000_with_camera_labels.tfrecord', './data/waymo/train/segment-10723911392655396041_860_000_880_000_with_camera_labels.tfrecord', './data/waymo/train/segment-10724020115992582208_7660_400_7680_400_with_camera_labels.tfrecord', './data/waymo/train/segment-10750135302241325253_180_000_200_000_with_camera_labels.tfrecord', './data/waymo/train/segment-10923963890428322967_1445_000_1465_000_with_camera_labels.tfrecord', './data/waymo/train/segment-10786629299947667143_3440_000_3460_000_with_camera_labels.tfrecord', './data/waymo/train/segment-10793018113277660068_2714_540_2734_540_with_camera_labels.tfrecord', './data/waymo/train/segment-1083056852838271990_4080_000_4100_000_with_camera_labels.tfrecord', './data/waymo/train/segment-10876852935525353526_1640_000_1660_000_with_camera_labels.tfrecord', './data/waymo/train/segment-10964956617027590844_1584_680_1604_680_with_camera_labels.tfrecord', './data/waymo/train/segment-11004685739714500220_2300_000_2320_000_with_camera_labels.tfrecord', './data/waymo/train/segment-11070802577416161387_740_000_760_000_with_camera_labels.tfrecord', './data/waymo/train/segment-11017034898130016754_697_830_717_830_with_camera_labels.tfrecord', './data/waymo/train/segment-11199484219241918646_2810_030_2830_030_with_camera_labels.tfrecord', './data/waymo/train/segment-11113047206980595400_2560_000_2580_000_with_camera_labels.tfrecord', './data/waymo/train/segment-11236550977973464715_3620_000_3640_000_with_camera_labels.tfrecord', './data/waymo/train/segment-11318901554551149504_520_000_540_000_with_camera_labels.tfrecord', './data/waymo/train/segment-11355519273066561009_5323_000_5343_000_with_camera_labels.tfrecord', './data/waymo/train/segment-11343624116265195592_5910_530_5930_530_with_camera_labels.tfrecord', './data/waymo/train/segment-11454085070345530663_1905_000_1925_000_with_camera_labels.tfrecord', './data/waymo/train/segment-11252086830380107152_1540_000_1560_000_with_camera_labels.tfrecord', './data/waymo/train/segment-11388947676680954806_5427_320_5447_320_with_camera_labels.tfrecord', './data/waymo/train/segment-11566385337103696871_5740_000_5760_000_with_camera_labels.tfrecord', './data/waymo/train/segment-11588853832866011756_2184_462_2204_462_with_camera_labels.tfrecord', './data/waymo/train/segment-1146261869236413282_1680_000_1700_000_with_camera_labels.tfrecord', './data/waymo/train/segment-11918003324473417938_1400_000_1420_000_with_camera_labels.tfrecord', './data/waymo/train/segment-1172406780360799916_1660_000_1680_000_with_camera_labels.tfrecord', './data/waymo/train/segment-11799592541704458019_9828_750_9848_750_with_camera_labels.tfrecord', './data/waymo/train/segment-11674150664140226235_680_000_700_000_with_camera_labels.tfrecord', './data/waymo/train/segment-11839652018869852123_2565_000_2585_000_with_camera_labels.tfrecord', './data/waymo/train/segment-11847506886204460250_1640_000_1660_000_with_camera_labels.tfrecord', './data/waymo/train/segment-11925224148023145510_1040_000_1060_000_with_camera_labels.tfrecord', './data/waymo/train/segment-11928449532664718059_1200_000_1220_000_with_camera_labels.tfrecord', './data/waymo/train/segment-11967272535264406807_580_000_600_000_with_camera_labels.tfrecord', './data/waymo/train/segment-12161824480686739258_1813_380_1833_380_with_camera_labels.tfrecord', './data/waymo/train/segment-12027892938363296829_4086_280_4106_280_with_camera_labels.tfrecord']\n",
            "I1221 03:07:15.393644 139859838478208 dataset_builder.py:80] Reading record datasets for input file: ['./data/waymo/train/segment-10153695247769592104_787_000_807_000_with_camera_labels.tfrecord', './data/waymo/train/segment-1005081002024129653_5313_150_5333_150_with_camera_labels.tfrecord', './data/waymo/train/segment-10094743350625019937_3420_000_3440_000_with_camera_labels.tfrecord', './data/waymo/train/segment-10017090168044687777_6380_000_6400_000_with_camera_labels.tfrecord', './data/waymo/train/segment-10061305430875486848_1080_000_1100_000_with_camera_labels.tfrecord', './data/waymo/train/segment-1022527355599519580_4866_960_4886_960_with_camera_labels.tfrecord', './data/waymo/train/segment-10226164909075980558_180_000_200_000_with_camera_labels.tfrecord', './data/waymo/train/segment-10241508783381919015_2889_360_2909_360_with_camera_labels.tfrecord', './data/waymo/train/segment-10231929575853664160_1160_000_1180_000_with_camera_labels.tfrecord', './data/waymo/train/segment-10206293520369375008_2796_800_2816_800_with_camera_labels.tfrecord', './data/waymo/train/segment-10235335145367115211_5420_000_5440_000_with_camera_labels.tfrecord', './data/waymo/train/segment-10444454289801298640_4360_000_4380_000_with_camera_labels.tfrecord', './data/waymo/train/segment-10275144660749673822_5755_561_5775_561_with_camera_labels.tfrecord', './data/waymo/train/segment-10455472356147194054_1560_000_1580_000_with_camera_labels.tfrecord', './data/waymo/train/segment-10327752107000040525_1120_000_1140_000_with_camera_labels.tfrecord', './data/waymo/train/segment-10485926982439064520_4980_000_5000_000_with_camera_labels.tfrecord', './data/waymo/train/segment-10517728057304349900_3360_000_3380_000_with_camera_labels.tfrecord', './data/waymo/train/segment-10526338824408452410_5714_660_5734_660_with_camera_labels.tfrecord', './data/waymo/train/segment-10500357041547037089_1474_800_1494_800_with_camera_labels.tfrecord', './data/waymo/train/segment-10588771936253546636_2300_000_2320_000_with_camera_labels.tfrecord', './data/waymo/train/segment-10664823084372323928_4360_000_4380_000_with_camera_labels.tfrecord', './data/waymo/train/segment-10625026498155904401_200_000_220_000_with_camera_labels.tfrecord', './data/waymo/train/segment-10770759614217273359_1465_000_1485_000_with_camera_labels.tfrecord', './data/waymo/train/segment-10723911392655396041_860_000_880_000_with_camera_labels.tfrecord', './data/waymo/train/segment-10724020115992582208_7660_400_7680_400_with_camera_labels.tfrecord', './data/waymo/train/segment-10750135302241325253_180_000_200_000_with_camera_labels.tfrecord', './data/waymo/train/segment-10923963890428322967_1445_000_1465_000_with_camera_labels.tfrecord', './data/waymo/train/segment-10786629299947667143_3440_000_3460_000_with_camera_labels.tfrecord', './data/waymo/train/segment-10793018113277660068_2714_540_2734_540_with_camera_labels.tfrecord', './data/waymo/train/segment-1083056852838271990_4080_000_4100_000_with_camera_labels.tfrecord', './data/waymo/train/segment-10876852935525353526_1640_000_1660_000_with_camera_labels.tfrecord', './data/waymo/train/segment-10964956617027590844_1584_680_1604_680_with_camera_labels.tfrecord', './data/waymo/train/segment-11004685739714500220_2300_000_2320_000_with_camera_labels.tfrecord', './data/waymo/train/segment-11070802577416161387_740_000_760_000_with_camera_labels.tfrecord', './data/waymo/train/segment-11017034898130016754_697_830_717_830_with_camera_labels.tfrecord', './data/waymo/train/segment-11199484219241918646_2810_030_2830_030_with_camera_labels.tfrecord', './data/waymo/train/segment-11113047206980595400_2560_000_2580_000_with_camera_labels.tfrecord', './data/waymo/train/segment-11236550977973464715_3620_000_3640_000_with_camera_labels.tfrecord', './data/waymo/train/segment-11318901554551149504_520_000_540_000_with_camera_labels.tfrecord', './data/waymo/train/segment-11355519273066561009_5323_000_5343_000_with_camera_labels.tfrecord', './data/waymo/train/segment-11343624116265195592_5910_530_5930_530_with_camera_labels.tfrecord', './data/waymo/train/segment-11454085070345530663_1905_000_1925_000_with_camera_labels.tfrecord', './data/waymo/train/segment-11252086830380107152_1540_000_1560_000_with_camera_labels.tfrecord', './data/waymo/train/segment-11388947676680954806_5427_320_5447_320_with_camera_labels.tfrecord', './data/waymo/train/segment-11566385337103696871_5740_000_5760_000_with_camera_labels.tfrecord', './data/waymo/train/segment-11588853832866011756_2184_462_2204_462_with_camera_labels.tfrecord', './data/waymo/train/segment-1146261869236413282_1680_000_1700_000_with_camera_labels.tfrecord', './data/waymo/train/segment-11918003324473417938_1400_000_1420_000_with_camera_labels.tfrecord', './data/waymo/train/segment-1172406780360799916_1660_000_1680_000_with_camera_labels.tfrecord', './data/waymo/train/segment-11799592541704458019_9828_750_9848_750_with_camera_labels.tfrecord', './data/waymo/train/segment-11674150664140226235_680_000_700_000_with_camera_labels.tfrecord', './data/waymo/train/segment-11839652018869852123_2565_000_2585_000_with_camera_labels.tfrecord', './data/waymo/train/segment-11847506886204460250_1640_000_1660_000_with_camera_labels.tfrecord', './data/waymo/train/segment-11925224148023145510_1040_000_1060_000_with_camera_labels.tfrecord', './data/waymo/train/segment-11928449532664718059_1200_000_1220_000_with_camera_labels.tfrecord', './data/waymo/train/segment-11967272535264406807_580_000_600_000_with_camera_labels.tfrecord', './data/waymo/train/segment-12161824480686739258_1813_380_1833_380_with_camera_labels.tfrecord', './data/waymo/train/segment-12027892938363296829_4086_280_4106_280_with_camera_labels.tfrecord']\n",
            "INFO:tensorflow:Number of filenames to read: 58\n",
            "I1221 03:07:15.479982 139859838478208 dataset_builder.py:81] Number of filenames to read: 58\n",
            "WARNING:tensorflow:num_readers has been reduced to 58 to match input file shards.\n",
            "W1221 03:07:15.480210 139859838478208 dataset_builder.py:88] num_readers has been reduced to 58 to match input file shards.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:105: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n",
            "W1221 03:07:15.484682 139859838478208 deprecation.py:347] From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:105: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:237: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "W1221 03:07:15.508976 139859838478208 deprecation.py:347] From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:237: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1096: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "W1221 03:07:24.491933 139859838478208 deprecation.py:347] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1096: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1096: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
            "W1221 03:07:28.429719 139859838478208 deprecation.py:347] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1096: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py:465: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W1221 03:07:30.559711 139859838478208 deprecation.py:347] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py:465: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "/usr/local/lib/python3.7/dist-packages/keras/backend.py:414: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
            "  warnings.warn('`tf.keras.backend.set_learning_phase` is deprecated and '\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I1221 03:08:19.606279 139859838478208 cross_device_ops.py:621] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I1221 03:08:19.607802 139859838478208 cross_device_ops.py:621] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I1221 03:08:19.610500 139859838478208 cross_device_ops.py:621] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I1221 03:08:19.611639 139859838478208 cross_device_ops.py:621] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I1221 03:08:19.614329 139859838478208 cross_device_ops.py:621] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I1221 03:08:19.615463 139859838478208 cross_device_ops.py:621] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I1221 03:08:19.618737 139859838478208 cross_device_ops.py:621] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I1221 03:08:19.619892 139859838478208 cross_device_ops.py:621] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I1221 03:08:19.622101 139859838478208 cross_device_ops.py:621] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I1221 03:08:19.623227 139859838478208 cross_device_ops.py:621] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/deprecation.py:620: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use fn_output_signature instead\n",
            "W1221 03:08:21.054713 139853509404416 deprecation.py:551] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/deprecation.py:620: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use fn_output_signature instead\n",
            "2021-12-21 03:09:05.458369: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.08GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
            "2021-12-21 03:09:05.583481: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.11GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
            "INFO:tensorflow:Step 100 per-step time 2.017s\n",
            "I1221 03:11:42.274853 139859838478208 model_lib_v2.py:707] Step 100 per-step time 2.017s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.65213364,\n",
            " 'Loss/localization_loss': 0.73072696,\n",
            " 'Loss/regularization_loss': 0.30466002,\n",
            " 'Loss/total_loss': 1.6875207,\n",
            " 'learning_rate': 0.014666351}\n",
            "I1221 03:11:42.275305 139859838478208 model_lib_v2.py:708] {'Loss/classification_loss': 0.65213364,\n",
            " 'Loss/localization_loss': 0.73072696,\n",
            " 'Loss/regularization_loss': 0.30466002,\n",
            " 'Loss/total_loss': 1.6875207,\n",
            " 'learning_rate': 0.014666351}\n",
            "INFO:tensorflow:Step 200 per-step time 1.555s\n",
            "I1221 03:14:17.712811 139859838478208 model_lib_v2.py:707] Step 200 per-step time 1.555s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.5948247,\n",
            " 'Loss/localization_loss': 0.5946176,\n",
            " 'Loss/regularization_loss': 0.3088794,\n",
            " 'Loss/total_loss': 1.4983217,\n",
            " 'learning_rate': 0.0159997}\n",
            "I1221 03:14:17.713302 139859838478208 model_lib_v2.py:708] {'Loss/classification_loss': 0.5948247,\n",
            " 'Loss/localization_loss': 0.5946176,\n",
            " 'Loss/regularization_loss': 0.3088794,\n",
            " 'Loss/total_loss': 1.4983217,\n",
            " 'learning_rate': 0.0159997}\n",
            "INFO:tensorflow:Step 300 per-step time 1.555s\n",
            "I1221 03:16:53.204155 139859838478208 model_lib_v2.py:707] Step 300 per-step time 1.555s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.34034097,\n",
            " 'Loss/localization_loss': 0.49534306,\n",
            " 'Loss/regularization_loss': 0.30759078,\n",
            " 'Loss/total_loss': 1.1432748,\n",
            " 'learning_rate': 0.01733305}\n",
            "I1221 03:16:53.204545 139859838478208 model_lib_v2.py:708] {'Loss/classification_loss': 0.34034097,\n",
            " 'Loss/localization_loss': 0.49534306,\n",
            " 'Loss/regularization_loss': 0.30759078,\n",
            " 'Loss/total_loss': 1.1432748,\n",
            " 'learning_rate': 0.01733305}\n",
            "INFO:tensorflow:Step 400 per-step time 1.555s\n",
            "I1221 03:19:28.720767 139859838478208 model_lib_v2.py:707] Step 400 per-step time 1.555s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.435017,\n",
            " 'Loss/localization_loss': 0.4813533,\n",
            " 'Loss/regularization_loss': 0.30629835,\n",
            " 'Loss/total_loss': 1.2226686,\n",
            " 'learning_rate': 0.0186664}\n",
            "I1221 03:19:28.721133 139859838478208 model_lib_v2.py:708] {'Loss/classification_loss': 0.435017,\n",
            " 'Loss/localization_loss': 0.4813533,\n",
            " 'Loss/regularization_loss': 0.30629835,\n",
            " 'Loss/total_loss': 1.2226686,\n",
            " 'learning_rate': 0.0186664}\n",
            "INFO:tensorflow:Step 500 per-step time 1.555s\n",
            "I1221 03:22:04.202973 139859838478208 model_lib_v2.py:707] Step 500 per-step time 1.555s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.39411366,\n",
            " 'Loss/localization_loss': 0.44022164,\n",
            " 'Loss/regularization_loss': 0.30353948,\n",
            " 'Loss/total_loss': 1.1378748,\n",
            " 'learning_rate': 0.01999975}\n",
            "I1221 03:22:04.203354 139859838478208 model_lib_v2.py:708] {'Loss/classification_loss': 0.39411366,\n",
            " 'Loss/localization_loss': 0.44022164,\n",
            " 'Loss/regularization_loss': 0.30353948,\n",
            " 'Loss/total_loss': 1.1378748,\n",
            " 'learning_rate': 0.01999975}\n",
            "INFO:tensorflow:Step 600 per-step time 1.557s\n",
            "I1221 03:24:39.891630 139859838478208 model_lib_v2.py:707] Step 600 per-step time 1.557s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.4274475,\n",
            " 'Loss/localization_loss': 0.50885916,\n",
            " 'Loss/regularization_loss': 0.30075076,\n",
            " 'Loss/total_loss': 1.2370574,\n",
            " 'learning_rate': 0.0213331}\n",
            "I1221 03:24:39.892086 139859838478208 model_lib_v2.py:708] {'Loss/classification_loss': 0.4274475,\n",
            " 'Loss/localization_loss': 0.50885916,\n",
            " 'Loss/regularization_loss': 0.30075076,\n",
            " 'Loss/total_loss': 1.2370574,\n",
            " 'learning_rate': 0.0213331}\n",
            "INFO:tensorflow:Step 700 per-step time 1.557s\n",
            "I1221 03:27:15.620349 139859838478208 model_lib_v2.py:707] Step 700 per-step time 1.557s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.35189173,\n",
            " 'Loss/localization_loss': 0.41456118,\n",
            " 'Loss/regularization_loss': 0.29846203,\n",
            " 'Loss/total_loss': 1.064915,\n",
            " 'learning_rate': 0.02266645}\n",
            "I1221 03:27:15.620768 139859838478208 model_lib_v2.py:708] {'Loss/classification_loss': 0.35189173,\n",
            " 'Loss/localization_loss': 0.41456118,\n",
            " 'Loss/regularization_loss': 0.29846203,\n",
            " 'Loss/total_loss': 1.064915,\n",
            " 'learning_rate': 0.02266645}\n",
            "INFO:tensorflow:Step 800 per-step time 1.565s\n",
            "I1221 03:29:52.089606 139859838478208 model_lib_v2.py:707] Step 800 per-step time 1.565s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.45141676,\n",
            " 'Loss/localization_loss': 0.46055433,\n",
            " 'Loss/regularization_loss': 0.2955697,\n",
            " 'Loss/total_loss': 1.2075408,\n",
            " 'learning_rate': 0.023999799}\n",
            "I1221 03:29:52.089979 139859838478208 model_lib_v2.py:708] {'Loss/classification_loss': 0.45141676,\n",
            " 'Loss/localization_loss': 0.46055433,\n",
            " 'Loss/regularization_loss': 0.2955697,\n",
            " 'Loss/total_loss': 1.2075408,\n",
            " 'learning_rate': 0.023999799}\n",
            "INFO:tensorflow:Step 900 per-step time 1.567s\n",
            "I1221 03:32:28.785842 139859838478208 model_lib_v2.py:707] Step 900 per-step time 1.567s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.4309383,\n",
            " 'Loss/localization_loss': 0.5183359,\n",
            " 'Loss/regularization_loss': 0.29280695,\n",
            " 'Loss/total_loss': 1.2420812,\n",
            " 'learning_rate': 0.025333151}\n",
            "I1221 03:32:28.786219 139859838478208 model_lib_v2.py:708] {'Loss/classification_loss': 0.4309383,\n",
            " 'Loss/localization_loss': 0.5183359,\n",
            " 'Loss/regularization_loss': 0.29280695,\n",
            " 'Loss/total_loss': 1.2420812,\n",
            " 'learning_rate': 0.025333151}\n",
            "INFO:tensorflow:Step 1000 per-step time 1.567s\n",
            "I1221 03:35:05.467082 139859838478208 model_lib_v2.py:707] Step 1000 per-step time 1.567s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.23801406,\n",
            " 'Loss/localization_loss': 0.2827291,\n",
            " 'Loss/regularization_loss': 0.2897859,\n",
            " 'Loss/total_loss': 0.810529,\n",
            " 'learning_rate': 0.0266665}\n",
            "I1221 03:35:05.467494 139859838478208 model_lib_v2.py:708] {'Loss/classification_loss': 0.23801406,\n",
            " 'Loss/localization_loss': 0.2827291,\n",
            " 'Loss/regularization_loss': 0.2897859,\n",
            " 'Loss/total_loss': 0.810529,\n",
            " 'learning_rate': 0.0266665}\n",
            "INFO:tensorflow:Step 1100 per-step time 1.564s\n",
            "I1221 03:37:41.908882 139859838478208 model_lib_v2.py:707] Step 1100 per-step time 1.564s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.34441876,\n",
            " 'Loss/localization_loss': 0.47910258,\n",
            " 'Loss/regularization_loss': 0.28665882,\n",
            " 'Loss/total_loss': 1.1101801,\n",
            " 'learning_rate': 0.02799985}\n",
            "I1221 03:37:41.909251 139859838478208 model_lib_v2.py:708] {'Loss/classification_loss': 0.34441876,\n",
            " 'Loss/localization_loss': 0.47910258,\n",
            " 'Loss/regularization_loss': 0.28665882,\n",
            " 'Loss/total_loss': 1.1101801,\n",
            " 'learning_rate': 0.02799985}\n",
            "INFO:tensorflow:Step 1200 per-step time 1.565s\n",
            "I1221 03:40:18.397264 139859838478208 model_lib_v2.py:707] Step 1200 per-step time 1.565s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.30869454,\n",
            " 'Loss/localization_loss': 0.40266797,\n",
            " 'Loss/regularization_loss': 0.28402272,\n",
            " 'Loss/total_loss': 0.99538517,\n",
            " 'learning_rate': 0.0293332}\n",
            "I1221 03:40:18.397797 139859838478208 model_lib_v2.py:708] {'Loss/classification_loss': 0.30869454,\n",
            " 'Loss/localization_loss': 0.40266797,\n",
            " 'Loss/regularization_loss': 0.28402272,\n",
            " 'Loss/total_loss': 0.99538517,\n",
            " 'learning_rate': 0.0293332}\n",
            "INFO:tensorflow:Step 1300 per-step time 1.567s\n",
            "I1221 03:42:55.070264 139859838478208 model_lib_v2.py:707] Step 1300 per-step time 1.567s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.23314062,\n",
            " 'Loss/localization_loss': 0.35147783,\n",
            " 'Loss/regularization_loss': 0.281424,\n",
            " 'Loss/total_loss': 0.86604244,\n",
            " 'learning_rate': 0.03066655}\n",
            "I1221 03:42:55.070635 139859838478208 model_lib_v2.py:708] {'Loss/classification_loss': 0.23314062,\n",
            " 'Loss/localization_loss': 0.35147783,\n",
            " 'Loss/regularization_loss': 0.281424,\n",
            " 'Loss/total_loss': 0.86604244,\n",
            " 'learning_rate': 0.03066655}\n",
            "INFO:tensorflow:Step 1400 per-step time 1.564s\n",
            "I1221 03:45:31.521111 139859838478208 model_lib_v2.py:707] Step 1400 per-step time 1.564s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.2782928,\n",
            " 'Loss/localization_loss': 0.47618085,\n",
            " 'Loss/regularization_loss': 0.2790956,\n",
            " 'Loss/total_loss': 1.0335693,\n",
            " 'learning_rate': 0.0319999}\n",
            "I1221 03:45:31.521471 139859838478208 model_lib_v2.py:708] {'Loss/classification_loss': 0.2782928,\n",
            " 'Loss/localization_loss': 0.47618085,\n",
            " 'Loss/regularization_loss': 0.2790956,\n",
            " 'Loss/total_loss': 1.0335693,\n",
            " 'learning_rate': 0.0319999}\n",
            "INFO:tensorflow:Step 1500 per-step time 1.564s\n",
            "I1221 03:48:07.873385 139859838478208 model_lib_v2.py:707] Step 1500 per-step time 1.564s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.24572213,\n",
            " 'Loss/localization_loss': 0.30168307,\n",
            " 'Loss/regularization_loss': 0.27713308,\n",
            " 'Loss/total_loss': 0.82453823,\n",
            " 'learning_rate': 0.03333325}\n",
            "I1221 03:48:07.873770 139859838478208 model_lib_v2.py:708] {'Loss/classification_loss': 0.24572213,\n",
            " 'Loss/localization_loss': 0.30168307,\n",
            " 'Loss/regularization_loss': 0.27713308,\n",
            " 'Loss/total_loss': 0.82453823,\n",
            " 'learning_rate': 0.03333325}\n",
            "INFO:tensorflow:Step 1600 per-step time 1.566s\n",
            "I1221 03:50:44.465587 139859838478208 model_lib_v2.py:707] Step 1600 per-step time 1.566s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.25635293,\n",
            " 'Loss/localization_loss': 0.29945555,\n",
            " 'Loss/regularization_loss': 0.27470767,\n",
            " 'Loss/total_loss': 0.83051616,\n",
            " 'learning_rate': 0.034666598}\n",
            "I1221 03:50:44.465990 139859838478208 model_lib_v2.py:708] {'Loss/classification_loss': 0.25635293,\n",
            " 'Loss/localization_loss': 0.29945555,\n",
            " 'Loss/regularization_loss': 0.27470767,\n",
            " 'Loss/total_loss': 0.83051616,\n",
            " 'learning_rate': 0.034666598}\n",
            "INFO:tensorflow:Step 1700 per-step time 1.563s\n",
            "I1221 03:53:20.773261 139859838478208 model_lib_v2.py:707] Step 1700 per-step time 1.563s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.25545081,\n",
            " 'Loss/localization_loss': 0.380094,\n",
            " 'Loss/regularization_loss': 0.27270707,\n",
            " 'Loss/total_loss': 0.9082519,\n",
            " 'learning_rate': 0.03599995}\n",
            "I1221 03:53:20.773653 139859838478208 model_lib_v2.py:708] {'Loss/classification_loss': 0.25545081,\n",
            " 'Loss/localization_loss': 0.380094,\n",
            " 'Loss/regularization_loss': 0.27270707,\n",
            " 'Loss/total_loss': 0.9082519,\n",
            " 'learning_rate': 0.03599995}\n",
            "INFO:tensorflow:Step 1800 per-step time 1.568s\n",
            "I1221 03:55:57.547816 139859838478208 model_lib_v2.py:707] Step 1800 per-step time 1.568s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.24377294,\n",
            " 'Loss/localization_loss': 0.26926914,\n",
            " 'Loss/regularization_loss': 0.27036095,\n",
            " 'Loss/total_loss': 0.78340304,\n",
            " 'learning_rate': 0.037333302}\n",
            "I1221 03:55:57.548191 139859838478208 model_lib_v2.py:708] {'Loss/classification_loss': 0.24377294,\n",
            " 'Loss/localization_loss': 0.26926914,\n",
            " 'Loss/regularization_loss': 0.27036095,\n",
            " 'Loss/total_loss': 0.78340304,\n",
            " 'learning_rate': 0.037333302}\n",
            "INFO:tensorflow:Step 1900 per-step time 1.565s\n",
            "I1221 03:58:34.019064 139859838478208 model_lib_v2.py:707] Step 1900 per-step time 1.565s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.34714174,\n",
            " 'Loss/localization_loss': 0.43764395,\n",
            " 'Loss/regularization_loss': 0.26823658,\n",
            " 'Loss/total_loss': 1.0530223,\n",
            " 'learning_rate': 0.03866665}\n",
            "I1221 03:58:34.019521 139859838478208 model_lib_v2.py:708] {'Loss/classification_loss': 0.34714174,\n",
            " 'Loss/localization_loss': 0.43764395,\n",
            " 'Loss/regularization_loss': 0.26823658,\n",
            " 'Loss/total_loss': 1.0530223,\n",
            " 'learning_rate': 0.03866665}\n",
            "INFO:tensorflow:Step 2000 per-step time 1.564s\n",
            "I1221 04:01:10.422527 139859838478208 model_lib_v2.py:707] Step 2000 per-step time 1.564s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.24188958,\n",
            " 'Loss/localization_loss': 0.31106323,\n",
            " 'Loss/regularization_loss': 0.26727638,\n",
            " 'Loss/total_loss': 0.8202292,\n",
            " 'learning_rate': 0.04}\n",
            "I1221 04:01:10.422969 139859838478208 model_lib_v2.py:708] {'Loss/classification_loss': 0.24188958,\n",
            " 'Loss/localization_loss': 0.31106323,\n",
            " 'Loss/regularization_loss': 0.26727638,\n",
            " 'Loss/total_loss': 0.8202292,\n",
            " 'learning_rate': 0.04}\n",
            "INFO:tensorflow:Step 2100 per-step time 1.588s\n",
            "I1221 04:03:49.220943 139859838478208 model_lib_v2.py:707] Step 2100 per-step time 1.588s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.25462672,\n",
            " 'Loss/localization_loss': 0.37910044,\n",
            " 'Loss/regularization_loss': 0.2649111,\n",
            " 'Loss/total_loss': 0.89863825,\n",
            " 'learning_rate': 0.039998136}\n",
            "I1221 04:03:49.221362 139859838478208 model_lib_v2.py:708] {'Loss/classification_loss': 0.25462672,\n",
            " 'Loss/localization_loss': 0.37910044,\n",
            " 'Loss/regularization_loss': 0.2649111,\n",
            " 'Loss/total_loss': 0.89863825,\n",
            " 'learning_rate': 0.039998136}\n",
            "INFO:tensorflow:Step 2200 per-step time 1.570s\n",
            "I1221 04:06:26.236575 139859838478208 model_lib_v2.py:707] Step 2200 per-step time 1.570s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.21651608,\n",
            " 'Loss/localization_loss': 0.22897342,\n",
            " 'Loss/regularization_loss': 0.2626497,\n",
            " 'Loss/total_loss': 0.7081392,\n",
            " 'learning_rate': 0.039992537}\n",
            "I1221 04:06:26.236997 139859838478208 model_lib_v2.py:708] {'Loss/classification_loss': 0.21651608,\n",
            " 'Loss/localization_loss': 0.22897342,\n",
            " 'Loss/regularization_loss': 0.2626497,\n",
            " 'Loss/total_loss': 0.7081392,\n",
            " 'learning_rate': 0.039992537}\n",
            "INFO:tensorflow:Step 2300 per-step time 1.564s\n",
            "I1221 04:09:02.619034 139859838478208 model_lib_v2.py:707] Step 2300 per-step time 1.564s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.2798921,\n",
            " 'Loss/localization_loss': 0.33696765,\n",
            " 'Loss/regularization_loss': 0.25925946,\n",
            " 'Loss/total_loss': 0.8761192,\n",
            " 'learning_rate': 0.03998321}\n",
            "I1221 04:09:02.619483 139859838478208 model_lib_v2.py:708] {'Loss/classification_loss': 0.2798921,\n",
            " 'Loss/localization_loss': 0.33696765,\n",
            " 'Loss/regularization_loss': 0.25925946,\n",
            " 'Loss/total_loss': 0.8761192,\n",
            " 'learning_rate': 0.03998321}\n",
            "INFO:tensorflow:Step 2400 per-step time 1.567s\n",
            "I1221 04:11:39.342633 139859838478208 model_lib_v2.py:707] Step 2400 per-step time 1.567s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.3084902,\n",
            " 'Loss/localization_loss': 0.3889732,\n",
            " 'Loss/regularization_loss': 0.25745776,\n",
            " 'Loss/total_loss': 0.9549211,\n",
            " 'learning_rate': 0.039970152}\n",
            "I1221 04:11:39.343049 139859838478208 model_lib_v2.py:708] {'Loss/classification_loss': 0.3084902,\n",
            " 'Loss/localization_loss': 0.3889732,\n",
            " 'Loss/regularization_loss': 0.25745776,\n",
            " 'Loss/total_loss': 0.9549211,\n",
            " 'learning_rate': 0.039970152}\n",
            "INFO:tensorflow:Step 2500 per-step time 1.568s\n",
            "I1221 04:14:16.148423 139859838478208 model_lib_v2.py:707] Step 2500 per-step time 1.568s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.19980437,\n",
            " 'Loss/localization_loss': 0.2554271,\n",
            " 'Loss/regularization_loss': 0.2548037,\n",
            " 'Loss/total_loss': 0.71003515,\n",
            " 'learning_rate': 0.039953373}\n",
            "I1221 04:14:16.148839 139859838478208 model_lib_v2.py:708] {'Loss/classification_loss': 0.19980437,\n",
            " 'Loss/localization_loss': 0.2554271,\n",
            " 'Loss/regularization_loss': 0.2548037,\n",
            " 'Loss/total_loss': 0.71003515,\n",
            " 'learning_rate': 0.039953373}\n",
            "INFO:tensorflow:Step 2600 per-step time 1.565s\n",
            "I1221 04:16:52.679143 139859838478208 model_lib_v2.py:707] Step 2600 per-step time 1.565s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.19080721,\n",
            " 'Loss/localization_loss': 0.18998529,\n",
            " 'Loss/regularization_loss': 0.2513787,\n",
            " 'Loss/total_loss': 0.63217115,\n",
            " 'learning_rate': 0.03993287}\n",
            "I1221 04:16:52.679539 139859838478208 model_lib_v2.py:708] {'Loss/classification_loss': 0.19080721,\n",
            " 'Loss/localization_loss': 0.18998529,\n",
            " 'Loss/regularization_loss': 0.2513787,\n",
            " 'Loss/total_loss': 0.63217115,\n",
            " 'learning_rate': 0.03993287}\n",
            "INFO:tensorflow:Step 2700 per-step time 1.568s\n",
            "I1221 04:19:29.448074 139859838478208 model_lib_v2.py:707] Step 2700 per-step time 1.568s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.19329262,\n",
            " 'Loss/localization_loss': 0.19279993,\n",
            " 'Loss/regularization_loss': 0.24898794,\n",
            " 'Loss/total_loss': 0.63508046,\n",
            " 'learning_rate': 0.039908648}\n",
            "I1221 04:19:29.448486 139859838478208 model_lib_v2.py:708] {'Loss/classification_loss': 0.19329262,\n",
            " 'Loss/localization_loss': 0.19279993,\n",
            " 'Loss/regularization_loss': 0.24898794,\n",
            " 'Loss/total_loss': 0.63508046,\n",
            " 'learning_rate': 0.039908648}\n",
            "INFO:tensorflow:Step 2800 per-step time 1.570s\n",
            "I1221 04:22:06.421321 139859838478208 model_lib_v2.py:707] Step 2800 per-step time 1.570s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.2110702,\n",
            " 'Loss/localization_loss': 0.24685603,\n",
            " 'Loss/regularization_loss': 0.24600396,\n",
            " 'Loss/total_loss': 0.70393014,\n",
            " 'learning_rate': 0.039880715}\n",
            "I1221 04:22:06.421711 139859838478208 model_lib_v2.py:708] {'Loss/classification_loss': 0.2110702,\n",
            " 'Loss/localization_loss': 0.24685603,\n",
            " 'Loss/regularization_loss': 0.24600396,\n",
            " 'Loss/total_loss': 0.70393014,\n",
            " 'learning_rate': 0.039880715}\n",
            "INFO:tensorflow:Step 2900 per-step time 1.569s\n",
            "I1221 04:24:43.332936 139859838478208 model_lib_v2.py:707] Step 2900 per-step time 1.569s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.23946507,\n",
            " 'Loss/localization_loss': 0.32775545,\n",
            " 'Loss/regularization_loss': 0.2432873,\n",
            " 'Loss/total_loss': 0.8105078,\n",
            " 'learning_rate': 0.039849065}\n",
            "I1221 04:24:43.333313 139859838478208 model_lib_v2.py:708] {'Loss/classification_loss': 0.23946507,\n",
            " 'Loss/localization_loss': 0.32775545,\n",
            " 'Loss/regularization_loss': 0.2432873,\n",
            " 'Loss/total_loss': 0.8105078,\n",
            " 'learning_rate': 0.039849065}\n",
            "INFO:tensorflow:Step 3000 per-step time 1.570s\n",
            "I1221 04:27:20.336701 139859838478208 model_lib_v2.py:707] Step 3000 per-step time 1.570s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.18746264,\n",
            " 'Loss/localization_loss': 0.23358701,\n",
            " 'Loss/regularization_loss': 0.24146608,\n",
            " 'Loss/total_loss': 0.66251576,\n",
            " 'learning_rate': 0.03981372}\n",
            "I1221 04:27:20.337182 139859838478208 model_lib_v2.py:708] {'Loss/classification_loss': 0.18746264,\n",
            " 'Loss/localization_loss': 0.23358701,\n",
            " 'Loss/regularization_loss': 0.24146608,\n",
            " 'Loss/total_loss': 0.66251576,\n",
            " 'learning_rate': 0.03981372}\n",
            "INFO:tensorflow:Step 3100 per-step time 1.569s\n",
            "I1221 04:29:57.253812 139859838478208 model_lib_v2.py:707] Step 3100 per-step time 1.569s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.19929619,\n",
            " 'Loss/localization_loss': 0.24073377,\n",
            " 'Loss/regularization_loss': 0.23931134,\n",
            " 'Loss/total_loss': 0.6793413,\n",
            " 'learning_rate': 0.03977467}\n",
            "I1221 04:29:57.254217 139859838478208 model_lib_v2.py:708] {'Loss/classification_loss': 0.19929619,\n",
            " 'Loss/localization_loss': 0.24073377,\n",
            " 'Loss/regularization_loss': 0.23931134,\n",
            " 'Loss/total_loss': 0.6793413,\n",
            " 'learning_rate': 0.03977467}\n",
            "INFO:tensorflow:Step 3200 per-step time 1.569s\n",
            "I1221 04:32:34.203995 139859838478208 model_lib_v2.py:707] Step 3200 per-step time 1.569s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.27830517,\n",
            " 'Loss/localization_loss': 0.3009702,\n",
            " 'Loss/regularization_loss': 0.23735954,\n",
            " 'Loss/total_loss': 0.8166349,\n",
            " 'learning_rate': 0.03973194}\n",
            "I1221 04:32:34.204373 139859838478208 model_lib_v2.py:708] {'Loss/classification_loss': 0.27830517,\n",
            " 'Loss/localization_loss': 0.3009702,\n",
            " 'Loss/regularization_loss': 0.23735954,\n",
            " 'Loss/total_loss': 0.8166349,\n",
            " 'learning_rate': 0.03973194}\n",
            "INFO:tensorflow:Step 3300 per-step time 1.568s\n",
            "I1221 04:35:10.979799 139859838478208 model_lib_v2.py:707] Step 3300 per-step time 1.568s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.23302522,\n",
            " 'Loss/localization_loss': 0.27590588,\n",
            " 'Loss/regularization_loss': 0.23596615,\n",
            " 'Loss/total_loss': 0.74489725,\n",
            " 'learning_rate': 0.03968552}\n",
            "I1221 04:35:10.980258 139859838478208 model_lib_v2.py:708] {'Loss/classification_loss': 0.23302522,\n",
            " 'Loss/localization_loss': 0.27590588,\n",
            " 'Loss/regularization_loss': 0.23596615,\n",
            " 'Loss/total_loss': 0.74489725,\n",
            " 'learning_rate': 0.03968552}\n",
            "INFO:tensorflow:Step 3400 per-step time 1.565s\n",
            "I1221 04:37:47.470633 139859838478208 model_lib_v2.py:707] Step 3400 per-step time 1.565s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.2189039,\n",
            " 'Loss/localization_loss': 0.24276567,\n",
            " 'Loss/regularization_loss': 0.23375297,\n",
            " 'Loss/total_loss': 0.69542253,\n",
            " 'learning_rate': 0.039635435}\n",
            "I1221 04:37:47.471039 139859838478208 model_lib_v2.py:708] {'Loss/classification_loss': 0.2189039,\n",
            " 'Loss/localization_loss': 0.24276567,\n",
            " 'Loss/regularization_loss': 0.23375297,\n",
            " 'Loss/total_loss': 0.69542253,\n",
            " 'learning_rate': 0.039635435}\n",
            "INFO:tensorflow:Step 3500 per-step time 1.567s\n",
            "I1221 04:40:24.128169 139859838478208 model_lib_v2.py:707] Step 3500 per-step time 1.567s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.23671283,\n",
            " 'Loss/localization_loss': 0.3338838,\n",
            " 'Loss/regularization_loss': 0.23113903,\n",
            " 'Loss/total_loss': 0.80173564,\n",
            " 'learning_rate': 0.03958168}\n",
            "I1221 04:40:24.128582 139859838478208 model_lib_v2.py:708] {'Loss/classification_loss': 0.23671283,\n",
            " 'Loss/localization_loss': 0.3338838,\n",
            " 'Loss/regularization_loss': 0.23113903,\n",
            " 'Loss/total_loss': 0.80173564,\n",
            " 'learning_rate': 0.03958168}\n",
            "INFO:tensorflow:Step 3600 per-step time 1.567s\n",
            "I1221 04:43:00.869004 139859838478208 model_lib_v2.py:707] Step 3600 per-step time 1.567s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.20801203,\n",
            " 'Loss/localization_loss': 0.30058232,\n",
            " 'Loss/regularization_loss': 0.22974819,\n",
            " 'Loss/total_loss': 0.7383425,\n",
            " 'learning_rate': 0.039524276}\n",
            "I1221 04:43:00.869537 139859838478208 model_lib_v2.py:708] {'Loss/classification_loss': 0.20801203,\n",
            " 'Loss/localization_loss': 0.30058232,\n",
            " 'Loss/regularization_loss': 0.22974819,\n",
            " 'Loss/total_loss': 0.7383425,\n",
            " 'learning_rate': 0.039524276}\n",
            "INFO:tensorflow:Step 3700 per-step time 1.564s\n",
            "I1221 04:45:37.276521 139859838478208 model_lib_v2.py:707] Step 3700 per-step time 1.564s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.16145079,\n",
            " 'Loss/localization_loss': 0.17492576,\n",
            " 'Loss/regularization_loss': 0.22789711,\n",
            " 'Loss/total_loss': 0.56427366,\n",
            " 'learning_rate': 0.03946323}\n",
            "I1221 04:45:37.276933 139859838478208 model_lib_v2.py:708] {'Loss/classification_loss': 0.16145079,\n",
            " 'Loss/localization_loss': 0.17492576,\n",
            " 'Loss/regularization_loss': 0.22789711,\n",
            " 'Loss/total_loss': 0.56427366,\n",
            " 'learning_rate': 0.03946323}\n",
            "INFO:tensorflow:Step 3800 per-step time 1.567s\n",
            "I1221 04:48:13.996910 139859838478208 model_lib_v2.py:707] Step 3800 per-step time 1.567s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.19604655,\n",
            " 'Loss/localization_loss': 0.18847016,\n",
            " 'Loss/regularization_loss': 0.22590394,\n",
            " 'Loss/total_loss': 0.61042064,\n",
            " 'learning_rate': 0.039398547}\n",
            "I1221 04:48:13.997323 139859838478208 model_lib_v2.py:708] {'Loss/classification_loss': 0.19604655,\n",
            " 'Loss/localization_loss': 0.18847016,\n",
            " 'Loss/regularization_loss': 0.22590394,\n",
            " 'Loss/total_loss': 0.61042064,\n",
            " 'learning_rate': 0.039398547}\n",
            "INFO:tensorflow:Step 3900 per-step time 1.567s\n",
            "I1221 04:50:50.706631 139859838478208 model_lib_v2.py:707] Step 3900 per-step time 1.567s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.25108403,\n",
            " 'Loss/localization_loss': 0.37021974,\n",
            " 'Loss/regularization_loss': 0.22635736,\n",
            " 'Loss/total_loss': 0.84766114,\n",
            " 'learning_rate': 0.039330248}\n",
            "I1221 04:50:50.707036 139859838478208 model_lib_v2.py:708] {'Loss/classification_loss': 0.25108403,\n",
            " 'Loss/localization_loss': 0.37021974,\n",
            " 'Loss/regularization_loss': 0.22635736,\n",
            " 'Loss/total_loss': 0.84766114,\n",
            " 'learning_rate': 0.039330248}\n",
            "INFO:tensorflow:Step 4000 per-step time 1.569s\n",
            "I1221 04:53:27.567588 139859838478208 model_lib_v2.py:707] Step 4000 per-step time 1.569s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.22765805,\n",
            " 'Loss/localization_loss': 0.33026943,\n",
            " 'Loss/regularization_loss': 0.22412011,\n",
            " 'Loss/total_loss': 0.7820476,\n",
            " 'learning_rate': 0.039258346}\n",
            "I1221 04:53:27.568009 139859838478208 model_lib_v2.py:708] {'Loss/classification_loss': 0.22765805,\n",
            " 'Loss/localization_loss': 0.33026943,\n",
            " 'Loss/regularization_loss': 0.22412011,\n",
            " 'Loss/total_loss': 0.7820476,\n",
            " 'learning_rate': 0.039258346}\n",
            "INFO:tensorflow:Step 4100 per-step time 1.583s\n",
            "I1221 04:56:05.899389 139859838478208 model_lib_v2.py:707] Step 4100 per-step time 1.583s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.18047084,\n",
            " 'Loss/localization_loss': 0.18182634,\n",
            " 'Loss/regularization_loss': 0.22341205,\n",
            " 'Loss/total_loss': 0.5857092,\n",
            " 'learning_rate': 0.03918285}\n",
            "I1221 04:56:05.899900 139859838478208 model_lib_v2.py:708] {'Loss/classification_loss': 0.18047084,\n",
            " 'Loss/localization_loss': 0.18182634,\n",
            " 'Loss/regularization_loss': 0.22341205,\n",
            " 'Loss/total_loss': 0.5857092,\n",
            " 'learning_rate': 0.03918285}\n",
            "INFO:tensorflow:Step 4200 per-step time 1.565s\n",
            "I1221 04:58:42.418787 139859838478208 model_lib_v2.py:707] Step 4200 per-step time 1.565s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.18592575,\n",
            " 'Loss/localization_loss': 0.1966313,\n",
            " 'Loss/regularization_loss': 0.22214817,\n",
            " 'Loss/total_loss': 0.6047052,\n",
            " 'learning_rate': 0.03910377}\n",
            "I1221 04:58:42.419171 139859838478208 model_lib_v2.py:708] {'Loss/classification_loss': 0.18592575,\n",
            " 'Loss/localization_loss': 0.1966313,\n",
            " 'Loss/regularization_loss': 0.22214817,\n",
            " 'Loss/total_loss': 0.6047052,\n",
            " 'learning_rate': 0.03910377}\n",
            "INFO:tensorflow:Step 4300 per-step time 1.565s\n",
            "I1221 05:01:18.917348 139859838478208 model_lib_v2.py:707] Step 4300 per-step time 1.565s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.23580654,\n",
            " 'Loss/localization_loss': 0.29277653,\n",
            " 'Loss/regularization_loss': 0.22010142,\n",
            " 'Loss/total_loss': 0.74868447,\n",
            " 'learning_rate': 0.039021127}\n",
            "I1221 05:01:18.917743 139859838478208 model_lib_v2.py:708] {'Loss/classification_loss': 0.23580654,\n",
            " 'Loss/localization_loss': 0.29277653,\n",
            " 'Loss/regularization_loss': 0.22010142,\n",
            " 'Loss/total_loss': 0.74868447,\n",
            " 'learning_rate': 0.039021127}\n",
            "INFO:tensorflow:Step 4400 per-step time 1.563s\n",
            "I1221 05:03:55.201129 139859838478208 model_lib_v2.py:707] Step 4400 per-step time 1.563s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.16850623,\n",
            " 'Loss/localization_loss': 0.19485274,\n",
            " 'Loss/regularization_loss': 0.21872362,\n",
            " 'Loss/total_loss': 0.5820826,\n",
            " 'learning_rate': 0.03893494}\n",
            "I1221 05:03:55.201558 139859838478208 model_lib_v2.py:708] {'Loss/classification_loss': 0.16850623,\n",
            " 'Loss/localization_loss': 0.19485274,\n",
            " 'Loss/regularization_loss': 0.21872362,\n",
            " 'Loss/total_loss': 0.5820826,\n",
            " 'learning_rate': 0.03893494}\n",
            "INFO:tensorflow:Step 4500 per-step time 1.570s\n",
            "I1221 05:06:32.171263 139859838478208 model_lib_v2.py:707] Step 4500 per-step time 1.570s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.19767736,\n",
            " 'Loss/localization_loss': 0.22500637,\n",
            " 'Loss/regularization_loss': 0.21707273,\n",
            " 'Loss/total_loss': 0.63975644,\n",
            " 'learning_rate': 0.03884522}\n",
            "I1221 05:06:32.171648 139859838478208 model_lib_v2.py:708] {'Loss/classification_loss': 0.19767736,\n",
            " 'Loss/localization_loss': 0.22500637,\n",
            " 'Loss/regularization_loss': 0.21707273,\n",
            " 'Loss/total_loss': 0.63975644,\n",
            " 'learning_rate': 0.03884522}\n",
            "INFO:tensorflow:Step 4600 per-step time 1.569s\n",
            "I1221 05:09:09.089849 139859838478208 model_lib_v2.py:707] Step 4600 per-step time 1.569s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.17085204,\n",
            " 'Loss/localization_loss': 0.18922698,\n",
            " 'Loss/regularization_loss': 0.2153706,\n",
            " 'Loss/total_loss': 0.5754496,\n",
            " 'learning_rate': 0.03875198}\n",
            "I1221 05:09:09.090195 139859838478208 model_lib_v2.py:708] {'Loss/classification_loss': 0.17085204,\n",
            " 'Loss/localization_loss': 0.18922698,\n",
            " 'Loss/regularization_loss': 0.2153706,\n",
            " 'Loss/total_loss': 0.5754496,\n",
            " 'learning_rate': 0.03875198}\n",
            "INFO:tensorflow:Step 4700 per-step time 1.573s\n",
            "I1221 05:11:46.438989 139859838478208 model_lib_v2.py:707] Step 4700 per-step time 1.573s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.19585197,\n",
            " 'Loss/localization_loss': 0.2784162,\n",
            " 'Loss/regularization_loss': 0.21409494,\n",
            " 'Loss/total_loss': 0.6883631,\n",
            " 'learning_rate': 0.038655244}\n",
            "I1221 05:11:46.439458 139859838478208 model_lib_v2.py:708] {'Loss/classification_loss': 0.19585197,\n",
            " 'Loss/localization_loss': 0.2784162,\n",
            " 'Loss/regularization_loss': 0.21409494,\n",
            " 'Loss/total_loss': 0.6883631,\n",
            " 'learning_rate': 0.038655244}\n",
            "INFO:tensorflow:Step 4800 per-step time 1.568s\n",
            "I1221 05:14:23.191336 139859838478208 model_lib_v2.py:707] Step 4800 per-step time 1.568s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.18103142,\n",
            " 'Loss/localization_loss': 0.17867616,\n",
            " 'Loss/regularization_loss': 0.21280846,\n",
            " 'Loss/total_loss': 0.5725161,\n",
            " 'learning_rate': 0.038555026}\n",
            "I1221 05:14:23.191843 139859838478208 model_lib_v2.py:708] {'Loss/classification_loss': 0.18103142,\n",
            " 'Loss/localization_loss': 0.17867616,\n",
            " 'Loss/regularization_loss': 0.21280846,\n",
            " 'Loss/total_loss': 0.5725161,\n",
            " 'learning_rate': 0.038555026}\n",
            "INFO:tensorflow:Step 4900 per-step time 1.568s\n",
            "I1221 05:17:00.019380 139859838478208 model_lib_v2.py:707] Step 4900 per-step time 1.568s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.22452217,\n",
            " 'Loss/localization_loss': 0.24183908,\n",
            " 'Loss/regularization_loss': 0.21181308,\n",
            " 'Loss/total_loss': 0.6781743,\n",
            " 'learning_rate': 0.038451348}\n",
            "I1221 05:17:00.019756 139859838478208 model_lib_v2.py:708] {'Loss/classification_loss': 0.22452217,\n",
            " 'Loss/localization_loss': 0.24183908,\n",
            " 'Loss/regularization_loss': 0.21181308,\n",
            " 'Loss/total_loss': 0.6781743,\n",
            " 'learning_rate': 0.038451348}\n",
            "INFO:tensorflow:Step 5000 per-step time 1.572s\n",
            "I1221 05:19:37.227093 139859838478208 model_lib_v2.py:707] Step 5000 per-step time 1.572s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.21384187,\n",
            " 'Loss/localization_loss': 0.31577465,\n",
            " 'Loss/regularization_loss': 0.21026169,\n",
            " 'Loss/total_loss': 0.73987824,\n",
            " 'learning_rate': 0.038344227}\n",
            "I1221 05:19:37.227476 139859838478208 model_lib_v2.py:708] {'Loss/classification_loss': 0.21384187,\n",
            " 'Loss/localization_loss': 0.31577465,\n",
            " 'Loss/regularization_loss': 0.21026169,\n",
            " 'Loss/total_loss': 0.73987824,\n",
            " 'learning_rate': 0.038344227}\n",
            "INFO:tensorflow:Step 5100 per-step time 1.572s\n",
            "I1221 05:22:14.418102 139859838478208 model_lib_v2.py:707] Step 5100 per-step time 1.572s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.19653864,\n",
            " 'Loss/localization_loss': 0.25816366,\n",
            " 'Loss/regularization_loss': 0.21025935,\n",
            " 'Loss/total_loss': 0.6649617,\n",
            " 'learning_rate': 0.03823368}\n",
            "I1221 05:22:14.418513 139859838478208 model_lib_v2.py:708] {'Loss/classification_loss': 0.19653864,\n",
            " 'Loss/localization_loss': 0.25816366,\n",
            " 'Loss/regularization_loss': 0.21025935,\n",
            " 'Loss/total_loss': 0.6649617,\n",
            " 'learning_rate': 0.03823368}\n",
            "INFO:tensorflow:Step 5200 per-step time 1.566s\n",
            "I1221 05:24:51.014141 139859838478208 model_lib_v2.py:707] Step 5200 per-step time 1.566s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.24013168,\n",
            " 'Loss/localization_loss': 0.2660665,\n",
            " 'Loss/regularization_loss': 0.20861432,\n",
            " 'Loss/total_loss': 0.7148125,\n",
            " 'learning_rate': 0.038119733}\n",
            "I1221 05:24:51.014509 139859838478208 model_lib_v2.py:708] {'Loss/classification_loss': 0.24013168,\n",
            " 'Loss/localization_loss': 0.2660665,\n",
            " 'Loss/regularization_loss': 0.20861432,\n",
            " 'Loss/total_loss': 0.7148125,\n",
            " 'learning_rate': 0.038119733}\n",
            "INFO:tensorflow:Step 5300 per-step time 1.570s\n",
            "I1221 05:27:27.992279 139859838478208 model_lib_v2.py:707] Step 5300 per-step time 1.570s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.13795424,\n",
            " 'Loss/localization_loss': 0.19420986,\n",
            " 'Loss/regularization_loss': 0.20707531,\n",
            " 'Loss/total_loss': 0.5392394,\n",
            " 'learning_rate': 0.03800241}\n",
            "I1221 05:27:27.992625 139859838478208 model_lib_v2.py:708] {'Loss/classification_loss': 0.13795424,\n",
            " 'Loss/localization_loss': 0.19420986,\n",
            " 'Loss/regularization_loss': 0.20707531,\n",
            " 'Loss/total_loss': 0.5392394,\n",
            " 'learning_rate': 0.03800241}\n",
            "INFO:tensorflow:Step 5400 per-step time 1.565s\n",
            "I1221 05:30:04.502942 139859838478208 model_lib_v2.py:707] Step 5400 per-step time 1.565s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.17455648,\n",
            " 'Loss/localization_loss': 0.26294354,\n",
            " 'Loss/regularization_loss': 0.20725167,\n",
            " 'Loss/total_loss': 0.64475167,\n",
            " 'learning_rate': 0.037881725}\n",
            "I1221 05:30:04.503368 139859838478208 model_lib_v2.py:708] {'Loss/classification_loss': 0.17455648,\n",
            " 'Loss/localization_loss': 0.26294354,\n",
            " 'Loss/regularization_loss': 0.20725167,\n",
            " 'Loss/total_loss': 0.64475167,\n",
            " 'learning_rate': 0.037881725}\n",
            "INFO:tensorflow:Step 5500 per-step time 1.563s\n",
            "I1221 05:32:40.817616 139859838478208 model_lib_v2.py:707] Step 5500 per-step time 1.563s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.2261705,\n",
            " 'Loss/localization_loss': 0.4819401,\n",
            " 'Loss/regularization_loss': 0.20580396,\n",
            " 'Loss/total_loss': 0.91391456,\n",
            " 'learning_rate': 0.037757702}\n",
            "I1221 05:32:40.818077 139859838478208 model_lib_v2.py:708] {'Loss/classification_loss': 0.2261705,\n",
            " 'Loss/localization_loss': 0.4819401,\n",
            " 'Loss/regularization_loss': 0.20580396,\n",
            " 'Loss/total_loss': 0.91391456,\n",
            " 'learning_rate': 0.037757702}\n",
            "INFO:tensorflow:Step 5600 per-step time 1.564s\n",
            "I1221 05:35:17.192241 139859838478208 model_lib_v2.py:707] Step 5600 per-step time 1.564s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.15647455,\n",
            " 'Loss/localization_loss': 0.19303685,\n",
            " 'Loss/regularization_loss': 0.20428933,\n",
            " 'Loss/total_loss': 0.5538007,\n",
            " 'learning_rate': 0.03763037}\n",
            "I1221 05:35:17.192671 139859838478208 model_lib_v2.py:708] {'Loss/classification_loss': 0.15647455,\n",
            " 'Loss/localization_loss': 0.19303685,\n",
            " 'Loss/regularization_loss': 0.20428933,\n",
            " 'Loss/total_loss': 0.5538007,\n",
            " 'learning_rate': 0.03763037}\n",
            "INFO:tensorflow:Step 5700 per-step time 1.564s\n",
            "I1221 05:37:53.603051 139859838478208 model_lib_v2.py:707] Step 5700 per-step time 1.564s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.16228624,\n",
            " 'Loss/localization_loss': 0.21866494,\n",
            " 'Loss/regularization_loss': 0.2028254,\n",
            " 'Loss/total_loss': 0.5837766,\n",
            " 'learning_rate': 0.03749975}\n",
            "I1221 05:37:53.603438 139859838478208 model_lib_v2.py:708] {'Loss/classification_loss': 0.16228624,\n",
            " 'Loss/localization_loss': 0.21866494,\n",
            " 'Loss/regularization_loss': 0.2028254,\n",
            " 'Loss/total_loss': 0.5837766,\n",
            " 'learning_rate': 0.03749975}\n",
            "INFO:tensorflow:Step 5800 per-step time 1.569s\n",
            "I1221 05:40:30.520830 139859838478208 model_lib_v2.py:707] Step 5800 per-step time 1.569s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.14894675,\n",
            " 'Loss/localization_loss': 0.20149334,\n",
            " 'Loss/regularization_loss': 0.2017177,\n",
            " 'Loss/total_loss': 0.55215776,\n",
            " 'learning_rate': 0.037365858}\n",
            "I1221 05:40:30.521188 139859838478208 model_lib_v2.py:708] {'Loss/classification_loss': 0.14894675,\n",
            " 'Loss/localization_loss': 0.20149334,\n",
            " 'Loss/regularization_loss': 0.2017177,\n",
            " 'Loss/total_loss': 0.55215776,\n",
            " 'learning_rate': 0.037365858}\n",
            "INFO:tensorflow:Step 5900 per-step time 1.569s\n",
            "I1221 05:43:07.450084 139859838478208 model_lib_v2.py:707] Step 5900 per-step time 1.569s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.19068016,\n",
            " 'Loss/localization_loss': 0.21235871,\n",
            " 'Loss/regularization_loss': 0.2002713,\n",
            " 'Loss/total_loss': 0.60331017,\n",
            " 'learning_rate': 0.03722873}\n",
            "I1221 05:43:07.450450 139859838478208 model_lib_v2.py:708] {'Loss/classification_loss': 0.19068016,\n",
            " 'Loss/localization_loss': 0.21235871,\n",
            " 'Loss/regularization_loss': 0.2002713,\n",
            " 'Loss/total_loss': 0.60331017,\n",
            " 'learning_rate': 0.03722873}\n",
            "INFO:tensorflow:Step 6000 per-step time 1.565s\n",
            "I1221 05:45:43.948173 139859838478208 model_lib_v2.py:707] Step 6000 per-step time 1.565s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.2318881,\n",
            " 'Loss/localization_loss': 0.2685826,\n",
            " 'Loss/regularization_loss': 0.1996849,\n",
            " 'Loss/total_loss': 0.7001556,\n",
            " 'learning_rate': 0.037088387}\n",
            "I1221 05:45:43.948539 139859838478208 model_lib_v2.py:708] {'Loss/classification_loss': 0.2318881,\n",
            " 'Loss/localization_loss': 0.2685826,\n",
            " 'Loss/regularization_loss': 0.1996849,\n",
            " 'Loss/total_loss': 0.7001556,\n",
            " 'learning_rate': 0.037088387}\n",
            "INFO:tensorflow:Step 6100 per-step time 1.590s\n",
            "I1221 05:48:22.946330 139859838478208 model_lib_v2.py:707] Step 6100 per-step time 1.590s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.17017217,\n",
            " 'Loss/localization_loss': 0.17377184,\n",
            " 'Loss/regularization_loss': 0.19942114,\n",
            " 'Loss/total_loss': 0.5433651,\n",
            " 'learning_rate': 0.036944855}\n",
            "I1221 05:48:22.946704 139859838478208 model_lib_v2.py:708] {'Loss/classification_loss': 0.17017217,\n",
            " 'Loss/localization_loss': 0.17377184,\n",
            " 'Loss/regularization_loss': 0.19942114,\n",
            " 'Loss/total_loss': 0.5433651,\n",
            " 'learning_rate': 0.036944855}\n",
            "INFO:tensorflow:Step 6200 per-step time 1.563s\n",
            "I1221 05:50:59.250953 139859838478208 model_lib_v2.py:707] Step 6200 per-step time 1.563s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.16745658,\n",
            " 'Loss/localization_loss': 0.1945879,\n",
            " 'Loss/regularization_loss': 0.19770771,\n",
            " 'Loss/total_loss': 0.5597522,\n",
            " 'learning_rate': 0.036798168}\n",
            "I1221 05:50:59.251335 139859838478208 model_lib_v2.py:708] {'Loss/classification_loss': 0.16745658,\n",
            " 'Loss/localization_loss': 0.1945879,\n",
            " 'Loss/regularization_loss': 0.19770771,\n",
            " 'Loss/total_loss': 0.5597522,\n",
            " 'learning_rate': 0.036798168}\n",
            "INFO:tensorflow:Step 6300 per-step time 1.569s\n",
            "I1221 05:53:36.134578 139859838478208 model_lib_v2.py:707] Step 6300 per-step time 1.569s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.23999634,\n",
            " 'Loss/localization_loss': 0.3152315,\n",
            " 'Loss/regularization_loss': 0.19676395,\n",
            " 'Loss/total_loss': 0.7519918,\n",
            " 'learning_rate': 0.03664834}\n",
            "I1221 05:53:36.134985 139859838478208 model_lib_v2.py:708] {'Loss/classification_loss': 0.23999634,\n",
            " 'Loss/localization_loss': 0.3152315,\n",
            " 'Loss/regularization_loss': 0.19676395,\n",
            " 'Loss/total_loss': 0.7519918,\n",
            " 'learning_rate': 0.03664834}\n",
            "INFO:tensorflow:Step 6400 per-step time 1.568s\n",
            "I1221 05:56:12.955335 139859838478208 model_lib_v2.py:707] Step 6400 per-step time 1.568s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.19864573,\n",
            " 'Loss/localization_loss': 0.2840134,\n",
            " 'Loss/regularization_loss': 0.19652984,\n",
            " 'Loss/total_loss': 0.67918897,\n",
            " 'learning_rate': 0.03649541}\n",
            "I1221 05:56:12.955765 139859838478208 model_lib_v2.py:708] {'Loss/classification_loss': 0.19864573,\n",
            " 'Loss/localization_loss': 0.2840134,\n",
            " 'Loss/regularization_loss': 0.19652984,\n",
            " 'Loss/total_loss': 0.67918897,\n",
            " 'learning_rate': 0.03649541}\n",
            "INFO:tensorflow:Step 6500 per-step time 1.566s\n",
            "I1221 05:58:49.542118 139859838478208 model_lib_v2.py:707] Step 6500 per-step time 1.566s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.20702727,\n",
            " 'Loss/localization_loss': 0.3234148,\n",
            " 'Loss/regularization_loss': 0.19503984,\n",
            " 'Loss/total_loss': 0.72548187,\n",
            " 'learning_rate': 0.0363394}\n",
            "I1221 05:58:49.542470 139859838478208 model_lib_v2.py:708] {'Loss/classification_loss': 0.20702727,\n",
            " 'Loss/localization_loss': 0.3234148,\n",
            " 'Loss/regularization_loss': 0.19503984,\n",
            " 'Loss/total_loss': 0.72548187,\n",
            " 'learning_rate': 0.0363394}\n",
            "INFO:tensorflow:Step 6600 per-step time 1.563s\n",
            "I1221 06:01:25.875049 139859838478208 model_lib_v2.py:707] Step 6600 per-step time 1.563s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.15107153,\n",
            " 'Loss/localization_loss': 0.18939586,\n",
            " 'Loss/regularization_loss': 0.19420967,\n",
            " 'Loss/total_loss': 0.534677,\n",
            " 'learning_rate': 0.03618034}\n",
            "I1221 06:01:25.875406 139859838478208 model_lib_v2.py:708] {'Loss/classification_loss': 0.15107153,\n",
            " 'Loss/localization_loss': 0.18939586,\n",
            " 'Loss/regularization_loss': 0.19420967,\n",
            " 'Loss/total_loss': 0.534677,\n",
            " 'learning_rate': 0.03618034}\n",
            "INFO:tensorflow:Step 6700 per-step time 1.568s\n",
            "I1221 06:04:02.665091 139859838478208 model_lib_v2.py:707] Step 6700 per-step time 1.568s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.15949881,\n",
            " 'Loss/localization_loss': 0.22616865,\n",
            " 'Loss/regularization_loss': 0.1939101,\n",
            " 'Loss/total_loss': 0.57957757,\n",
            " 'learning_rate': 0.03601826}\n",
            "I1221 06:04:02.665477 139859838478208 model_lib_v2.py:708] {'Loss/classification_loss': 0.15949881,\n",
            " 'Loss/localization_loss': 0.22616865,\n",
            " 'Loss/regularization_loss': 0.1939101,\n",
            " 'Loss/total_loss': 0.57957757,\n",
            " 'learning_rate': 0.03601826}\n",
            "INFO:tensorflow:Step 6800 per-step time 1.567s\n",
            "I1221 06:06:39.408583 139859838478208 model_lib_v2.py:707] Step 6800 per-step time 1.567s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.2536936,\n",
            " 'Loss/localization_loss': 0.29241198,\n",
            " 'Loss/regularization_loss': 0.19342873,\n",
            " 'Loss/total_loss': 0.7395344,\n",
            " 'learning_rate': 0.035853196}\n",
            "I1221 06:06:39.409042 139859838478208 model_lib_v2.py:708] {'Loss/classification_loss': 0.2536936,\n",
            " 'Loss/localization_loss': 0.29241198,\n",
            " 'Loss/regularization_loss': 0.19342873,\n",
            " 'Loss/total_loss': 0.7395344,\n",
            " 'learning_rate': 0.035853196}\n",
            "INFO:tensorflow:Step 6900 per-step time 1.567s\n",
            "I1221 06:09:16.060889 139859838478208 model_lib_v2.py:707] Step 6900 per-step time 1.567s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.14290789,\n",
            " 'Loss/localization_loss': 0.18961558,\n",
            " 'Loss/regularization_loss': 0.19301626,\n",
            " 'Loss/total_loss': 0.52553976,\n",
            " 'learning_rate': 0.035685178}\n",
            "I1221 06:09:16.061282 139859838478208 model_lib_v2.py:708] {'Loss/classification_loss': 0.14290789,\n",
            " 'Loss/localization_loss': 0.18961558,\n",
            " 'Loss/regularization_loss': 0.19301626,\n",
            " 'Loss/total_loss': 0.52553976,\n",
            " 'learning_rate': 0.035685178}\n",
            "INFO:tensorflow:Step 7000 per-step time 1.569s\n",
            "I1221 06:11:52.928996 139859838478208 model_lib_v2.py:707] Step 7000 per-step time 1.569s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.16519126,\n",
            " 'Loss/localization_loss': 0.20669806,\n",
            " 'Loss/regularization_loss': 0.19150428,\n",
            " 'Loss/total_loss': 0.5633936,\n",
            " 'learning_rate': 0.035514224}\n",
            "I1221 06:11:52.929430 139859838478208 model_lib_v2.py:708] {'Loss/classification_loss': 0.16519126,\n",
            " 'Loss/localization_loss': 0.20669806,\n",
            " 'Loss/regularization_loss': 0.19150428,\n",
            " 'Loss/total_loss': 0.5633936,\n",
            " 'learning_rate': 0.035514224}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python experiments/model_main_tf2.py --model_dir=training/reference/ --pipeline_config_path=training/reference/pipeline_new.config --checkpoint_dir=training/reference/"
      ],
      "metadata": {
        "id": "snUJz4f3Wkyt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1620ce43-fe06-4c52-9af6-bad26528961f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Forced number of epochs for all eval validations to be 1.\n",
            "W1221 08:15:21.765566 140699397666688 model_lib_v2.py:1090] Forced number of epochs for all eval validations to be 1.\n",
            "INFO:tensorflow:Maybe overwriting sample_1_of_n_eval_examples: None\n",
            "I1221 08:15:21.765934 140699397666688 config_util.py:552] Maybe overwriting sample_1_of_n_eval_examples: None\n",
            "INFO:tensorflow:Maybe overwriting use_bfloat16: False\n",
            "I1221 08:15:21.766102 140699397666688 config_util.py:552] Maybe overwriting use_bfloat16: False\n",
            "INFO:tensorflow:Maybe overwriting eval_num_epochs: 1\n",
            "I1221 08:15:21.766453 140699397666688 config_util.py:552] Maybe overwriting eval_num_epochs: 1\n",
            "WARNING:tensorflow:Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n",
            "W1221 08:15:21.766739 140699397666688 model_lib_v2.py:1111] Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n",
            "2021-12-21 08:15:24.369631: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "INFO:tensorflow:Reading unweighted datasets: ['./data/waymo/val/segment-1051897962568538022_238_170_258_170_with_camera_labels.tfrecord', './data/waymo/val/segment-12179768245749640056_5561_070_5581_070_with_camera_labels.tfrecord', './data/waymo/val/segment-10072140764565668044_4060_000_4080_000_with_camera_labels.tfrecord', './data/waymo/val/segment-11060291335850384275_3761_210_3781_210_with_camera_labels.tfrecord', './data/waymo/val/segment-11076364019363412893_1711_000_1731_000_with_camera_labels.tfrecord', './data/waymo/val/segment-1208303279778032257_1360_000_1380_000_with_camera_labels.tfrecord', './data/waymo/val/segment-11940460932056521663_1760_000_1780_000_with_camera_labels.tfrecord', './data/waymo/val/segment-10498013744573185290_1240_000_1260_000_with_camera_labels.tfrecord', './data/waymo/val/segment-10596949720463106554_1933_530_1953_530_with_camera_labels.tfrecord', './data/waymo/val/segment-11183906854663518829_2294_000_2314_000_with_camera_labels.tfrecord', './data/waymo/val/segment-11489533038039664633_4820_000_4840_000_with_camera_labels.tfrecord', './data/waymo/val/segment-11846396154240966170_3540_000_3560_000_with_camera_labels.tfrecord', './data/waymo/val/segment-11219370372259322863_5320_000_5340_000_with_camera_labels.tfrecord', './data/waymo/val/segment-10927752430968246422_4940_000_4960_000_with_camera_labels.tfrecord', './data/waymo/val/segment-11623618970700582562_2840_367_2860_367_with_camera_labels.tfrecord', './data/waymo/val/segment-10391312872392849784_4099_400_4119_400_with_camera_labels.tfrecord', './data/waymo/val/segment-10212406498497081993_5300_000_5320_000_with_camera_labels.tfrecord', './data/waymo/val/segment-11718898130355901268_2300_000_2320_000_with_camera_labels.tfrecord', './data/waymo/val/segment-10107710434105775874_760_000_780_000_with_camera_labels.tfrecord']\n",
            "I1221 08:15:24.735366 140699397666688 dataset_builder.py:163] Reading unweighted datasets: ['./data/waymo/val/segment-1051897962568538022_238_170_258_170_with_camera_labels.tfrecord', './data/waymo/val/segment-12179768245749640056_5561_070_5581_070_with_camera_labels.tfrecord', './data/waymo/val/segment-10072140764565668044_4060_000_4080_000_with_camera_labels.tfrecord', './data/waymo/val/segment-11060291335850384275_3761_210_3781_210_with_camera_labels.tfrecord', './data/waymo/val/segment-11076364019363412893_1711_000_1731_000_with_camera_labels.tfrecord', './data/waymo/val/segment-1208303279778032257_1360_000_1380_000_with_camera_labels.tfrecord', './data/waymo/val/segment-11940460932056521663_1760_000_1780_000_with_camera_labels.tfrecord', './data/waymo/val/segment-10498013744573185290_1240_000_1260_000_with_camera_labels.tfrecord', './data/waymo/val/segment-10596949720463106554_1933_530_1953_530_with_camera_labels.tfrecord', './data/waymo/val/segment-11183906854663518829_2294_000_2314_000_with_camera_labels.tfrecord', './data/waymo/val/segment-11489533038039664633_4820_000_4840_000_with_camera_labels.tfrecord', './data/waymo/val/segment-11846396154240966170_3540_000_3560_000_with_camera_labels.tfrecord', './data/waymo/val/segment-11219370372259322863_5320_000_5340_000_with_camera_labels.tfrecord', './data/waymo/val/segment-10927752430968246422_4940_000_4960_000_with_camera_labels.tfrecord', './data/waymo/val/segment-11623618970700582562_2840_367_2860_367_with_camera_labels.tfrecord', './data/waymo/val/segment-10391312872392849784_4099_400_4119_400_with_camera_labels.tfrecord', './data/waymo/val/segment-10212406498497081993_5300_000_5320_000_with_camera_labels.tfrecord', './data/waymo/val/segment-11718898130355901268_2300_000_2320_000_with_camera_labels.tfrecord', './data/waymo/val/segment-10107710434105775874_760_000_780_000_with_camera_labels.tfrecord']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['./data/waymo/val/segment-1051897962568538022_238_170_258_170_with_camera_labels.tfrecord', './data/waymo/val/segment-12179768245749640056_5561_070_5581_070_with_camera_labels.tfrecord', './data/waymo/val/segment-10072140764565668044_4060_000_4080_000_with_camera_labels.tfrecord', './data/waymo/val/segment-11060291335850384275_3761_210_3781_210_with_camera_labels.tfrecord', './data/waymo/val/segment-11076364019363412893_1711_000_1731_000_with_camera_labels.tfrecord', './data/waymo/val/segment-1208303279778032257_1360_000_1380_000_with_camera_labels.tfrecord', './data/waymo/val/segment-11940460932056521663_1760_000_1780_000_with_camera_labels.tfrecord', './data/waymo/val/segment-10498013744573185290_1240_000_1260_000_with_camera_labels.tfrecord', './data/waymo/val/segment-10596949720463106554_1933_530_1953_530_with_camera_labels.tfrecord', './data/waymo/val/segment-11183906854663518829_2294_000_2314_000_with_camera_labels.tfrecord', './data/waymo/val/segment-11489533038039664633_4820_000_4840_000_with_camera_labels.tfrecord', './data/waymo/val/segment-11846396154240966170_3540_000_3560_000_with_camera_labels.tfrecord', './data/waymo/val/segment-11219370372259322863_5320_000_5340_000_with_camera_labels.tfrecord', './data/waymo/val/segment-10927752430968246422_4940_000_4960_000_with_camera_labels.tfrecord', './data/waymo/val/segment-11623618970700582562_2840_367_2860_367_with_camera_labels.tfrecord', './data/waymo/val/segment-10391312872392849784_4099_400_4119_400_with_camera_labels.tfrecord', './data/waymo/val/segment-10212406498497081993_5300_000_5320_000_with_camera_labels.tfrecord', './data/waymo/val/segment-11718898130355901268_2300_000_2320_000_with_camera_labels.tfrecord', './data/waymo/val/segment-10107710434105775874_760_000_780_000_with_camera_labels.tfrecord']\n",
            "I1221 08:15:25.156636 140699397666688 dataset_builder.py:80] Reading record datasets for input file: ['./data/waymo/val/segment-1051897962568538022_238_170_258_170_with_camera_labels.tfrecord', './data/waymo/val/segment-12179768245749640056_5561_070_5581_070_with_camera_labels.tfrecord', './data/waymo/val/segment-10072140764565668044_4060_000_4080_000_with_camera_labels.tfrecord', './data/waymo/val/segment-11060291335850384275_3761_210_3781_210_with_camera_labels.tfrecord', './data/waymo/val/segment-11076364019363412893_1711_000_1731_000_with_camera_labels.tfrecord', './data/waymo/val/segment-1208303279778032257_1360_000_1380_000_with_camera_labels.tfrecord', './data/waymo/val/segment-11940460932056521663_1760_000_1780_000_with_camera_labels.tfrecord', './data/waymo/val/segment-10498013744573185290_1240_000_1260_000_with_camera_labels.tfrecord', './data/waymo/val/segment-10596949720463106554_1933_530_1953_530_with_camera_labels.tfrecord', './data/waymo/val/segment-11183906854663518829_2294_000_2314_000_with_camera_labels.tfrecord', './data/waymo/val/segment-11489533038039664633_4820_000_4840_000_with_camera_labels.tfrecord', './data/waymo/val/segment-11846396154240966170_3540_000_3560_000_with_camera_labels.tfrecord', './data/waymo/val/segment-11219370372259322863_5320_000_5340_000_with_camera_labels.tfrecord', './data/waymo/val/segment-10927752430968246422_4940_000_4960_000_with_camera_labels.tfrecord', './data/waymo/val/segment-11623618970700582562_2840_367_2860_367_with_camera_labels.tfrecord', './data/waymo/val/segment-10391312872392849784_4099_400_4119_400_with_camera_labels.tfrecord', './data/waymo/val/segment-10212406498497081993_5300_000_5320_000_with_camera_labels.tfrecord', './data/waymo/val/segment-11718898130355901268_2300_000_2320_000_with_camera_labels.tfrecord', './data/waymo/val/segment-10107710434105775874_760_000_780_000_with_camera_labels.tfrecord']\n",
            "INFO:tensorflow:Number of filenames to read: 19\n",
            "I1221 08:15:25.156940 140699397666688 dataset_builder.py:81] Number of filenames to read: 19\n",
            "WARNING:tensorflow:num_readers has been reduced to 19 to match input file shards.\n",
            "W1221 08:15:25.157111 140699397666688 dataset_builder.py:88] num_readers has been reduced to 19 to match input file shards.\n",
            "WARNING:tensorflow:`shuffle` is false, but the input data stream is still slightly shuffled since `num_readers` > 1.\n",
            "W1221 08:15:25.162119 140699397666688 dataset_builder.py:94] `shuffle` is false, but the input data stream is still slightly shuffled since `num_readers` > 1.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:105: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n",
            "W1221 08:15:25.163476 140699397666688 deprecation.py:347] From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:105: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:237: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "W1221 08:15:25.203436 140699397666688 deprecation.py:347] From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:237: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1096: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "W1221 08:15:31.176323 140699397666688 deprecation.py:347] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1096: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py:465: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W1221 08:15:32.547844 140699397666688 deprecation.py:347] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py:465: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "INFO:tensorflow:Waiting for new checkpoint at training/reference/\n",
            "I1221 08:15:36.508156 140699397666688 checkpoint_utils.py:140] Waiting for new checkpoint at training/reference/\n",
            "INFO:tensorflow:Found new checkpoint at training/reference/ckpt-4\n",
            "I1221 08:15:36.653686 140699397666688 checkpoint_utils.py:149] Found new checkpoint at training/reference/ckpt-4\n",
            "/usr/local/lib/python3.7/dist-packages/keras/backend.py:414: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
            "  warnings.warn('`tf.keras.backend.set_learning_phase` is deprecated and '\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/eval_util.py:929: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W1221 08:16:19.193721 140699397666688 deprecation.py:347] From /usr/local/lib/python3.7/dist-packages/object_detection/eval_util.py:929: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "INFO:tensorflow:Finished eval step 0\n",
            "I1221 08:16:19.214776 140699397666688 model_lib_v2.py:966] Finished eval step 0\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py:465: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "tf.py_func is deprecated in TF V2. Instead, there are two\n",
            "    options available in V2.\n",
            "    - tf.py_function takes a python function which manipulates tf eager\n",
            "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
            "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
            "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
            "    being differentiable using a gradient tape.\n",
            "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
            "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
            "    stateful argument making all functions stateful.\n",
            "    \n",
            "W1221 08:16:19.387274 140699397666688 deprecation.py:347] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py:465: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "tf.py_func is deprecated in TF V2. Instead, there are two\n",
            "    options available in V2.\n",
            "    - tf.py_function takes a python function which manipulates tf eager\n",
            "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
            "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
            "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
            "    being differentiable using a gradient tape.\n",
            "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
            "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
            "    stateful argument making all functions stateful.\n",
            "    \n",
            "INFO:tensorflow:Finished eval step 100\n",
            "I1221 08:16:44.703393 140699397666688 model_lib_v2.py:966] Finished eval step 100\n",
            "INFO:tensorflow:Finished eval step 200\n",
            "I1221 08:17:07.237227 140699397666688 model_lib_v2.py:966] Finished eval step 200\n",
            "INFO:tensorflow:Finished eval step 300\n",
            "I1221 08:17:29.829905 140699397666688 model_lib_v2.py:966] Finished eval step 300\n",
            "INFO:tensorflow:Performing evaluation on 380 images.\n",
            "I1221 08:17:47.450918 140699397666688 coco_evaluation.py:293] Performing evaluation on 380 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I1221 08:17:47.455646 140699397666688 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.02s)\n",
            "I1221 08:17:47.479344 140699397666688 coco_tools.py:138] DONE (t=0.02s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=20.09s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.43s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.088\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.174\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.083\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.035\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.229\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.276\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.020\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.090\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.140\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.084\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.297\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.442\n",
            "INFO:tensorflow:Eval metrics at step 6000\n",
            "I1221 08:18:08.045888 140699397666688 model_lib_v2.py:1015] Eval metrics at step 6000\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP: 0.087510\n",
            "I1221 08:18:08.067682 140699397666688 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP: 0.087510\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP@.50IOU: 0.173717\n",
            "I1221 08:18:08.069866 140699397666688 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP@.50IOU: 0.173717\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP@.75IOU: 0.083231\n",
            "I1221 08:18:08.071455 140699397666688 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP@.75IOU: 0.083231\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP (small): 0.035066\n",
            "I1221 08:18:08.073165 140699397666688 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP (small): 0.035066\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP (medium): 0.229130\n",
            "I1221 08:18:08.074729 140699397666688 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP (medium): 0.229130\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP (large): 0.275632\n",
            "I1221 08:18:08.076274 140699397666688 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP (large): 0.275632\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@1: 0.020097\n",
            "I1221 08:18:08.078085 140699397666688 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@1: 0.020097\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@10: 0.090205\n",
            "I1221 08:18:08.079869 140699397666688 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@10: 0.090205\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100: 0.139685\n",
            "I1221 08:18:08.081577 140699397666688 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@100: 0.139685\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100 (small): 0.084415\n",
            "I1221 08:18:08.083291 140699397666688 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@100 (small): 0.084415\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100 (medium): 0.296844\n",
            "I1221 08:18:08.084991 140699397666688 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@100 (medium): 0.296844\n",
            "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100 (large): 0.441519\n",
            "I1221 08:18:08.086969 140699397666688 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@100 (large): 0.441519\n",
            "INFO:tensorflow:\t+ Loss/localization_loss: 0.515666\n",
            "I1221 08:18:08.088441 140699397666688 model_lib_v2.py:1018] \t+ Loss/localization_loss: 0.515666\n",
            "INFO:tensorflow:\t+ Loss/classification_loss: 0.444973\n",
            "I1221 08:18:08.089986 140699397666688 model_lib_v2.py:1018] \t+ Loss/classification_loss: 0.444973\n",
            "INFO:tensorflow:\t+ Loss/regularization_loss: 0.199690\n",
            "I1221 08:18:08.091797 140699397666688 model_lib_v2.py:1018] \t+ Loss/regularization_loss: 0.199690\n",
            "INFO:tensorflow:\t+ Loss/total_loss: 1.160328\n",
            "I1221 08:18:08.093297 140699397666688 model_lib_v2.py:1018] \t+ Loss/total_loss: 1.160328\n",
            "INFO:tensorflow:Waiting for new checkpoint at training/reference/\n",
            "I1221 08:20:36.737876 140699397666688 checkpoint_utils.py:140] Waiting for new checkpoint at training/reference/\n",
            "INFO:tensorflow:Timed-out waiting for a checkpoint.\n",
            "I1221 08:21:35.898903 140699397666688 checkpoint_utils.py:203] Timed-out waiting for a checkpoint.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yn5_uV1HLvaz"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pathlib\n",
        "\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import io\n",
        "import scipy.misc\n",
        "import numpy as np\n",
        "from six import BytesIO\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "from six.moves.urllib.request import urlopen\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "tf.get_logger().setLevel('ERROR')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IogyryF2lFBL"
      },
      "source": [
        "## Utilities\n",
        "\n",
        "Run the following cell to create some utils that will be needed later:\n",
        "\n",
        "- Helper method to load an image\n",
        "- Map of Model Name to TF Hub handle\n",
        "- List of tuples with Human Keypoints for the COCO 2017 dataset. This is needed for models with keypoints."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "-y9R0Xllefec"
      },
      "outputs": [],
      "source": [
        "# @title Run this!!\n",
        "\n",
        "def load_image_into_numpy_array(path):\n",
        "  \"\"\"Load an image from file into a numpy array.\n",
        "\n",
        "  Puts image into numpy array to feed into tensorflow graph.\n",
        "  Note that by convention we put it into a numpy array with shape\n",
        "  (height, width, channels), where channels=3 for RGB.\n",
        "\n",
        "  Args:\n",
        "    path: the file path to the image\n",
        "\n",
        "  Returns:\n",
        "    uint8 numpy array with shape (img_height, img_width, 3)\n",
        "  \"\"\"\n",
        "  image = None\n",
        "  if(path.startswith('http')):\n",
        "    response = urlopen(path)\n",
        "    image_data = response.read()\n",
        "    image_data = BytesIO(image_data)\n",
        "    image = Image.open(image_data)\n",
        "  else:\n",
        "    image_data = tf.io.gfile.GFile(path, 'rb').read()\n",
        "    image = Image.open(BytesIO(image_data))\n",
        "\n",
        "  (im_width, im_height) = image.size\n",
        "  return np.array(image.getdata()).reshape(\n",
        "      (1, im_height, im_width, 3)).astype(np.uint8)\n",
        "\n",
        "\n",
        "ALL_MODELS = {\n",
        "'CenterNet HourGlass104 512x512' : 'https://tfhub.dev/tensorflow/centernet/hourglass_512x512/1',\n",
        "'CenterNet HourGlass104 Keypoints 512x512' : 'https://tfhub.dev/tensorflow/centernet/hourglass_512x512_kpts/1',\n",
        "'CenterNet HourGlass104 1024x1024' : 'https://tfhub.dev/tensorflow/centernet/hourglass_1024x1024/1',\n",
        "'CenterNet HourGlass104 Keypoints 1024x1024' : 'https://tfhub.dev/tensorflow/centernet/hourglass_1024x1024_kpts/1',\n",
        "'CenterNet Resnet50 V1 FPN 512x512' : 'https://tfhub.dev/tensorflow/centernet/resnet50v1_fpn_512x512/1',\n",
        "'CenterNet Resnet50 V1 FPN Keypoints 512x512' : 'https://tfhub.dev/tensorflow/centernet/resnet50v1_fpn_512x512_kpts/1',\n",
        "'CenterNet Resnet101 V1 FPN 512x512' : 'https://tfhub.dev/tensorflow/centernet/resnet101v1_fpn_512x512/1',\n",
        "'CenterNet Resnet50 V2 512x512' : 'https://tfhub.dev/tensorflow/centernet/resnet50v2_512x512/1',\n",
        "'CenterNet Resnet50 V2 Keypoints 512x512' : 'https://tfhub.dev/tensorflow/centernet/resnet50v2_512x512_kpts/1',\n",
        "'EfficientDet D0 512x512' : 'https://tfhub.dev/tensorflow/efficientdet/d0/1',\n",
        "'EfficientDet D1 640x640' : 'https://tfhub.dev/tensorflow/efficientdet/d1/1',\n",
        "'EfficientDet D2 768x768' : 'https://tfhub.dev/tensorflow/efficientdet/d2/1',\n",
        "'EfficientDet D3 896x896' : 'https://tfhub.dev/tensorflow/efficientdet/d3/1',\n",
        "'EfficientDet D4 1024x1024' : 'https://tfhub.dev/tensorflow/efficientdet/d4/1',\n",
        "'EfficientDet D5 1280x1280' : 'https://tfhub.dev/tensorflow/efficientdet/d5/1',\n",
        "'EfficientDet D6 1280x1280' : 'https://tfhub.dev/tensorflow/efficientdet/d6/1',\n",
        "'EfficientDet D7 1536x1536' : 'https://tfhub.dev/tensorflow/efficientdet/d7/1',\n",
        "'SSD MobileNet v2 320x320' : 'https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2',\n",
        "'SSD MobileNet V1 FPN 640x640' : 'https://tfhub.dev/tensorflow/ssd_mobilenet_v1/fpn_640x640/1',\n",
        "'SSD MobileNet V2 FPNLite 320x320' : 'https://tfhub.dev/tensorflow/ssd_mobilenet_v2/fpnlite_320x320/1',\n",
        "'SSD MobileNet V2 FPNLite 640x640' : 'https://tfhub.dev/tensorflow/ssd_mobilenet_v2/fpnlite_640x640/1',\n",
        "'SSD ResNet50 V1 FPN 640x640 (RetinaNet50)' : 'https://tfhub.dev/tensorflow/retinanet/resnet50_v1_fpn_640x640/1',\n",
        "'SSD ResNet50 V1 FPN 1024x1024 (RetinaNet50)' : 'https://tfhub.dev/tensorflow/retinanet/resnet50_v1_fpn_1024x1024/1',\n",
        "'SSD ResNet101 V1 FPN 640x640 (RetinaNet101)' : 'https://tfhub.dev/tensorflow/retinanet/resnet101_v1_fpn_640x640/1',\n",
        "'SSD ResNet101 V1 FPN 1024x1024 (RetinaNet101)' : 'https://tfhub.dev/tensorflow/retinanet/resnet101_v1_fpn_1024x1024/1',\n",
        "'SSD ResNet152 V1 FPN 640x640 (RetinaNet152)' : 'https://tfhub.dev/tensorflow/retinanet/resnet152_v1_fpn_640x640/1',\n",
        "'SSD ResNet152 V1 FPN 1024x1024 (RetinaNet152)' : 'https://tfhub.dev/tensorflow/retinanet/resnet152_v1_fpn_1024x1024/1',\n",
        "'Faster R-CNN ResNet50 V1 640x640' : 'https://tfhub.dev/tensorflow/faster_rcnn/resnet50_v1_640x640/1',\n",
        "'Faster R-CNN ResNet50 V1 1024x1024' : 'https://tfhub.dev/tensorflow/faster_rcnn/resnet50_v1_1024x1024/1',\n",
        "'Faster R-CNN ResNet50 V1 800x1333' : 'https://tfhub.dev/tensorflow/faster_rcnn/resnet50_v1_800x1333/1',\n",
        "'Faster R-CNN ResNet101 V1 640x640' : 'https://tfhub.dev/tensorflow/faster_rcnn/resnet101_v1_640x640/1',\n",
        "'Faster R-CNN ResNet101 V1 1024x1024' : 'https://tfhub.dev/tensorflow/faster_rcnn/resnet101_v1_1024x1024/1',\n",
        "'Faster R-CNN ResNet101 V1 800x1333' : 'https://tfhub.dev/tensorflow/faster_rcnn/resnet101_v1_800x1333/1',\n",
        "'Faster R-CNN ResNet152 V1 640x640' : 'https://tfhub.dev/tensorflow/faster_rcnn/resnet152_v1_640x640/1',\n",
        "'Faster R-CNN ResNet152 V1 1024x1024' : 'https://tfhub.dev/tensorflow/faster_rcnn/resnet152_v1_1024x1024/1',\n",
        "'Faster R-CNN ResNet152 V1 800x1333' : 'https://tfhub.dev/tensorflow/faster_rcnn/resnet152_v1_800x1333/1',\n",
        "'Faster R-CNN Inception ResNet V2 640x640' : 'https://tfhub.dev/tensorflow/faster_rcnn/inception_resnet_v2_640x640/1',\n",
        "'Faster R-CNN Inception ResNet V2 1024x1024' : 'https://tfhub.dev/tensorflow/faster_rcnn/inception_resnet_v2_1024x1024/1',\n",
        "'Mask R-CNN Inception ResNet V2 1024x1024' : 'https://tfhub.dev/tensorflow/mask_rcnn/inception_resnet_v2_1024x1024/1'\n",
        "}\n",
        "\n",
        "IMAGES_FOR_TEST = {\n",
        "  'Beach' : 'models/research/object_detection/test_images/image2.jpg',\n",
        "  'Dogs' : 'models/research/object_detection/test_images/image1.jpg',\n",
        "  # By Heiko Gorski, Source: https://commons.wikimedia.org/wiki/File:Naxos_Taverna.jpg\n",
        "  'Naxos Taverna' : 'https://upload.wikimedia.org/wikipedia/commons/6/60/Naxos_Taverna.jpg',\n",
        "  # Source: https://commons.wikimedia.org/wiki/File:The_Coleoptera_of_the_British_islands_(Plate_125)_(8592917784).jpg\n",
        "  'Beatles' : 'https://upload.wikimedia.org/wikipedia/commons/1/1b/The_Coleoptera_of_the_British_islands_%28Plate_125%29_%288592917784%29.jpg',\n",
        "  # By Américo Toledano, Source: https://commons.wikimedia.org/wiki/File:Biblioteca_Maim%C3%B3nides,_Campus_Universitario_de_Rabanales_007.jpg\n",
        "  'Phones' : 'https://upload.wikimedia.org/wikipedia/commons/thumb/0/0d/Biblioteca_Maim%C3%B3nides%2C_Campus_Universitario_de_Rabanales_007.jpg/1024px-Biblioteca_Maim%C3%B3nides%2C_Campus_Universitario_de_Rabanales_007.jpg',\n",
        "  # Source: https://commons.wikimedia.org/wiki/File:The_smaller_British_birds_(8053836633).jpg\n",
        "  'Birds' : 'https://upload.wikimedia.org/wikipedia/commons/0/09/The_smaller_British_birds_%288053836633%29.jpg',\n",
        "}\n",
        "\n",
        "COCO17_HUMAN_POSE_KEYPOINTS = [(0, 1),\n",
        " (0, 2),\n",
        " (1, 3),\n",
        " (2, 4),\n",
        " (0, 5),\n",
        " (0, 6),\n",
        " (5, 7),\n",
        " (7, 9),\n",
        " (6, 8),\n",
        " (8, 10),\n",
        " (5, 6),\n",
        " (5, 11),\n",
        " (6, 12),\n",
        " (11, 12),\n",
        " (11, 13),\n",
        " (13, 15),\n",
        " (12, 14),\n",
        " (14, 16)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "14bNk1gzh0TN"
      },
      "source": [
        "## Visualization tools\n",
        "\n",
        "To visualize the images with the proper detected boxes, keypoints and segmentation, we will use the TensorFlow Object Detection API. To install it we will clone the repo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "oi28cqGGFWnY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8de79e6-d41d-4780-d308-79ceecce55cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'models' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "# Clone the tensorflow models repository\n",
        "!git clone --depth 1 https://github.com/tensorflow/models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yX3pb_pXDjYA"
      },
      "source": [
        "Intalling the Object Detection API"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "NwdsBdGhFanc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64e81912-d51c-4a24-8a35-37e3867ad2a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists...\n",
            "Building dependency tree...\n",
            "Reading state information...\n",
            "protobuf-compiler is already the newest version (3.0.0-9.1ubuntu1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 37 not upgraded.\n",
            "Processing /content/gdrive/My Drive/home/workspace/models/research\n",
            "Collecting avro-python3\n",
            "  Downloading avro-python3-1.10.2.tar.gz (38 kB)\n",
            "Collecting apache-beam\n",
            "  Downloading apache_beam-2.34.0-cp37-cp37m-manylinux2010_x86_64.whl (9.8 MB)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (7.1.2)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (4.2.6)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (3.2.2)\n",
            "Requirement already satisfied: Cython in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (0.29.24)\n",
            "Requirement already satisfied: contextlib2 in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (0.5.5)\n",
            "Collecting tf-slim\n",
            "  Downloading tf_slim-1.1.0-py2.py3-none-any.whl (352 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.15.0)\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (2.0.3)\n",
            "Collecting lvis\n",
            "  Downloading lvis-0.5.3-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.4.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.1.5)\n",
            "Collecting tf-models-official>=2.5.1\n",
            "  Downloading tf_models_official-2.7.0-py2.py3-none-any.whl (1.8 MB)\n",
            "Collecting tensorflow_io\n",
            "  Downloading tensorflow_io-0.23.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (23.1 MB)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (2.7.0)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.19.5)\n",
            "Collecting py-cpuinfo>=3.3.0\n",
            "  Downloading py-cpuinfo-8.0.0.tar.gz (99 kB)\n",
            "Collecting tensorflow-addons\n",
            "  Downloading tensorflow_addons-0.15.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "Requirement already satisfied: psutil>=5.4.3 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (5.4.8)\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "Collecting sacrebleu\n",
            "  Downloading sacrebleu-2.0.0-py3-none-any.whl (90 kB)\n",
            "Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.0.1)\n",
            "Collecting opencv-python-headless\n",
            "  Downloading opencv_python_headless-4.5.4.60-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (47.6 MB)\n",
            "Requirement already satisfied: tensorflow-hub>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.12.0)\n",
            "Requirement already satisfied: google-api-python-client>=1.6.7 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.12.8)\n",
            "Collecting tensorflow-model-optimization>=0.4.1\n",
            "  Downloading tensorflow_model_optimization-0.7.0-py2.py3-none-any.whl (213 kB)\n",
            "Collecting tensorflow-text>=2.7.0\n",
            "  Downloading tensorflow_text-2.7.3-cp37-cp37m-manylinux2010_x86_64.whl (4.9 MB)\n",
            "Requirement already satisfied: kaggle>=1.3.9 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.5.12)\n",
            "Requirement already satisfied: tensorflow>=2.7.0 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (2.7.0)\n",
            "Collecting seqeval\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "Requirement already satisfied: oauth2client in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.1.3)\n",
            "Requirement already satisfied: gin-config in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.5.0)\n",
            "Requirement already satisfied: google-auth>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (1.35.0)\n",
            "Requirement already satisfied: google-api-core<2dev,>=1.21.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (1.26.3)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.0.4)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.15.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.17.4)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (3.0.1)\n",
            "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.23.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (1.53.0)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2018.9)\n",
            "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (57.4.0)\n",
            "Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (3.17.3)\n",
            "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (21.3)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (4.8)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.2.8)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (2.8.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (2021.10.8)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (1.24.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (4.62.3)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (5.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=14.3->google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (3.0.6)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.4.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.10)\n",
            "Requirement already satisfied: tensorboard~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (2.7.0)\n",
            "Requirement already satisfied: flatbuffers<3.0,>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (2.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (1.1.2)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (12.0.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (3.10.0.2)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (0.12.0)\n",
            "Requirement already satisfied: gast<0.5.0,>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (0.4.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (0.37.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (3.3.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (1.1.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (0.22.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (3.1.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.8,~=2.7.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (2.7.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (1.42.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (1.6.3)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (0.2.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (1.13.3)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (1.5.2)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (0.4.6)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (3.3.6)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (1.8.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (0.6.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (4.8.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.6->tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (3.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow>=2.7.0->tf-models-official>=2.5.1->object-detection==0.1) (3.1.1)\n",
            "Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-model-optimization>=0.4.1->tf-models-official>=2.5.1->object-detection==0.1) (0.1.6)\n",
            "Requirement already satisfied: pydot<2,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (1.3.0)\n",
            "Collecting requests<3.0.0dev,>=2.18.0\n",
            "  Downloading requests-2.26.0-py2.py3-none-any.whl (62 kB)\n",
            "Collecting future<1.0.0,>=0.18.2\n",
            "  Downloading future-0.18.2.tar.gz (829 kB)\n",
            "Requirement already satisfied: pymongo<4.0.0,>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (3.12.1)\n",
            "Collecting avro-python3\n",
            "  Downloading avro-python3-1.9.2.1.tar.gz (37 kB)\n",
            "Requirement already satisfied: pyarrow<6.0.0,>=0.15.1 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (3.0.0)\n",
            "Collecting hdfs<3.0.0,>=2.1.0\n",
            "  Downloading hdfs-2.6.0-py3-none-any.whl (33 kB)\n",
            "Collecting fastavro<2,>=0.21.4\n",
            "  Downloading fastavro-1.4.7-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)\n",
            "Collecting dill<0.3.2,>=0.3.1.1\n",
            "  Downloading dill-0.3.1.1.tar.gz (151 kB)\n",
            "Requirement already satisfied: crcmod<2.0,>=1.7 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (1.7)\n",
            "Collecting orjson<4.0\n",
            "  Downloading orjson-3.6.5-cp37-cp37m-manylinux_2_24_x86_64.whl (247 kB)\n",
            "Requirement already satisfied: docopt in /usr/local/lib/python3.7/dist-packages (from hdfs<3.0.0,>=2.1.0->apache-beam->object-detection==0.1) (0.6.2)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.0.8)\n",
            "Requirement already satisfied: opencv-python>=4.1.0.25 in /usr/local/lib/python3.7/dist-packages (from lvis->object-detection==0.1) (4.1.2.30)\n",
            "Requirement already satisfied: cycler>=0.10.0 in /usr/local/lib/python3.7/dist-packages (from lvis->object-detection==0.1) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from lvis->object-detection==0.1) (1.3.2)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (1.3)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from sacrebleu->tf-models-official>=2.5.1->object-detection==0.1) (2019.12.20)\n",
            "Collecting colorama\n",
            "  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n",
            "Collecting portalocker\n",
            "  Downloading portalocker-2.3.2-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.7/dist-packages (from sacrebleu->tf-models-official>=2.5.1->object-detection==0.1) (0.8.9)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from seqeval->tf-models-official>=2.5.1->object-detection==0.1) (1.0.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.5.1->object-detection==0.1) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.5.1->object-detection==0.1) (3.0.0)\n",
            "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons->tf-models-official>=2.5.1->object-detection==0.1) (2.7.1)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (2.3)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (1.4.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (5.4.0)\n",
            "Requirement already satisfied: attrs>=18.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (21.2.0)\n",
            "Collecting tensorflow-io-gcs-filesystem>=0.21.0\n",
            "  Downloading tensorflow_io_gcs_filesystem-0.23.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.1 MB)\n",
            "Building wheels for collected packages: object-detection, py-cpuinfo, avro-python3, dill, future, seqeval\n",
            "  Building wheel for object-detection (setup.py): started\n",
            "  Building wheel for object-detection (setup.py): finished with status 'done'\n",
            "  Created wheel for object-detection: filename=object_detection-0.1-py3-none-any.whl size=1683460 sha256=66e5a8a0306cf7aab9f2940e6406a55b8d695cf32ee6f796a60f1c8183fb6a51\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-rn53rzyn/wheels/7d/80/90/bfb7fff0692200a1a122b6ae6474b82d0ddfdd657dcc85f81b\n",
            "  Building wheel for py-cpuinfo (setup.py): started\n",
            "  Building wheel for py-cpuinfo (setup.py): finished with status 'done'\n",
            "  Created wheel for py-cpuinfo: filename=py_cpuinfo-8.0.0-py3-none-any.whl size=22258 sha256=10ce47761596f66101caa31a12e9717527b4beff2e38eef3a996e94c843a531c\n",
            "  Stored in directory: /root/.cache/pip/wheels/d2/f1/1f/041add21dc9c4220157f1bd2bd6afe1f1a49524c3396b94401\n",
            "  Building wheel for avro-python3 (setup.py): started\n",
            "  Building wheel for avro-python3 (setup.py): finished with status 'done'\n",
            "  Created wheel for avro-python3: filename=avro_python3-1.9.2.1-py3-none-any.whl size=43512 sha256=22a5fa0dae00b6a146181f419d2eb90cf77ebaef511c32e6a942e2b722657123\n",
            "  Stored in directory: /root/.cache/pip/wheels/bc/49/5f/fdb5b9d85055c478213e0158ac122b596816149a02d82e0ab1\n",
            "  Building wheel for dill (setup.py): started\n",
            "  Building wheel for dill (setup.py): finished with status 'done'\n",
            "  Created wheel for dill: filename=dill-0.3.1.1-py3-none-any.whl size=78546 sha256=cd0bc51bbd404a2a6944f52482b6a081a0d4b4152d0e0a1bf25d9aceb246c01a\n",
            "  Stored in directory: /root/.cache/pip/wheels/a4/61/fd/c57e374e580aa78a45ed78d5859b3a44436af17e22ca53284f\n",
            "  Building wheel for future (setup.py): started\n",
            "  Building wheel for future (setup.py): finished with status 'done'\n",
            "  Created wheel for future: filename=future-0.18.2-py3-none-any.whl size=491070 sha256=c6083587a50cfcf3b42618a3d1d1c6ab203ed54234ef462208d7063b505c54d9\n",
            "  Stored in directory: /root/.cache/pip/wheels/56/b0/fe/4410d17b32f1f0c3cf54cdfb2bc04d7b4b8f4ae377e2229ba0\n",
            "  Building wheel for seqeval (setup.py): started\n",
            "  Building wheel for seqeval (setup.py): finished with status 'done'\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16181 sha256=2a98bcfd16272db12180f38d771b1694e02c9173fa40c2cf0327591f96985c2d\n",
            "  Stored in directory: /root/.cache/pip/wheels/05/96/ee/7cac4e74f3b19e3158dce26a20a1c86b3533c43ec72a549fd7\n",
            "Successfully built object-detection py-cpuinfo avro-python3 dill future seqeval\n",
            "Installing collected packages: requests, tensorflow-io-gcs-filesystem, portalocker, future, dill, colorama, tf-slim, tensorflow-text, tensorflow-model-optimization, tensorflow-addons, seqeval, sentencepiece, sacrebleu, pyyaml, py-cpuinfo, orjson, opencv-python-headless, hdfs, fastavro, avro-python3, tf-models-official, tensorflow-io, lvis, apache-beam, object-detection\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "  Attempting uninstall: tensorflow-io-gcs-filesystem\n",
            "    Found existing installation: tensorflow-io-gcs-filesystem 0.22.0\n",
            "    Uninstalling tensorflow-io-gcs-filesystem-0.22.0:\n",
            "      Successfully uninstalled tensorflow-io-gcs-filesystem-0.22.0\n",
            "  Attempting uninstall: future\n",
            "    Found existing installation: future 0.16.0\n",
            "    Uninstalling future-0.16.0:\n",
            "      Successfully uninstalled future-0.16.0\n",
            "  Attempting uninstall: dill\n",
            "    Found existing installation: dill 0.3.4\n",
            "    Uninstalling dill-0.3.4:\n",
            "      Successfully uninstalled dill-0.3.4\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed apache-beam-2.34.0 avro-python3-1.9.2.1 colorama-0.4.4 dill-0.3.1.1 fastavro-1.4.7 future-0.18.2 hdfs-2.6.0 lvis-0.5.3 object-detection-0.1 opencv-python-headless-4.5.4.60 orjson-3.6.5 portalocker-2.3.2 py-cpuinfo-8.0.0 pyyaml-6.0 requests-2.26.0 sacrebleu-2.0.0 sentencepiece-0.1.96 seqeval-1.2.2 tensorflow-addons-0.15.0 tensorflow-io-0.23.1 tensorflow-io-gcs-filesystem-0.23.1 tensorflow-model-optimization-0.7.0 tensorflow-text-2.7.3 tf-models-official-2.7.0 tf-slim-1.1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "WARNING: apt does not have a stable CLI interface. Use with caution in scripts.\n",
            "\n",
            "  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n",
            "   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\n",
            "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "multiprocess 0.70.12.2 requires dill>=0.3.4, but you have dill 0.3.1.1 which is incompatible.\n",
            "google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.26.0 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "sudo apt install -y protobuf-compiler\n",
        "cd models/research/\n",
        "protoc object_detection/protos/*.proto --python_out=.\n",
        "cp object_detection/packages/tf2/setup.py .\n",
        "python -m pip install .\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3yDNgIx-kV7X"
      },
      "source": [
        "Now we can import the dependencies we will need later"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "2JCeQU3fkayh"
      },
      "outputs": [],
      "source": [
        "from object_detection.utils import label_map_util\n",
        "from object_detection.utils import visualization_utils as viz_utils\n",
        "from object_detection.utils import ops as utils_ops\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NKtD0IeclbL5"
      },
      "source": [
        "### Load label map data (for plotting).\n",
        "\n",
        "Label maps correspond index numbers to category names, so that when our convolution network predicts `5`, we know that this corresponds to `airplane`.  Here we use internal utility functions, but anything that returns a dictionary mapping integers to appropriate string labels would be fine.\n",
        "\n",
        "We are going, for simplicity, to load from the repository that we loaded the Object Detection API code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5mucYUS6exUJ"
      },
      "outputs": [],
      "source": [
        "PATH_TO_LABELS = './models/research/object_detection/data/mscoco_label_map.pbtxt'\n",
        "category_index = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS, use_display_name=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6917xnUSlp9x"
      },
      "source": [
        "## Build a detection model and load pre-trained model weights\n",
        "\n",
        "Here we will choose which Object Detection model we will use.\n",
        "Select the architecture and it will be loaded automatically.\n",
        "If you want to change the model to try other architectures later, just change the next cell and execute following ones.\n",
        "\n",
        "**Tip:** if you want to read more details about the selected model, you can follow the link (model handle) and read additional documentation on TF Hub. After you select a model, we will print the handle to make it easier."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HtwrSqvakTNn"
      },
      "outputs": [],
      "source": [
        "#@title Model Selection { display-mode: \"form\", run: \"auto\" }\n",
        "model_display_name = 'CenterNet HourGlass104 Keypoints 512x512' # @param ['CenterNet HourGlass104 512x512','CenterNet HourGlass104 Keypoints 512x512','CenterNet HourGlass104 1024x1024','CenterNet HourGlass104 Keypoints 1024x1024','CenterNet Resnet50 V1 FPN 512x512','CenterNet Resnet50 V1 FPN Keypoints 512x512','CenterNet Resnet101 V1 FPN 512x512','CenterNet Resnet50 V2 512x512','CenterNet Resnet50 V2 Keypoints 512x512','EfficientDet D0 512x512','EfficientDet D1 640x640','EfficientDet D2 768x768','EfficientDet D3 896x896','EfficientDet D4 1024x1024','EfficientDet D5 1280x1280','EfficientDet D6 1280x1280','EfficientDet D7 1536x1536','SSD MobileNet v2 320x320','SSD MobileNet V1 FPN 640x640','SSD MobileNet V2 FPNLite 320x320','SSD MobileNet V2 FPNLite 640x640','SSD ResNet50 V1 FPN 640x640 (RetinaNet50)','SSD ResNet50 V1 FPN 1024x1024 (RetinaNet50)','SSD ResNet101 V1 FPN 640x640 (RetinaNet101)','SSD ResNet101 V1 FPN 1024x1024 (RetinaNet101)','SSD ResNet152 V1 FPN 640x640 (RetinaNet152)','SSD ResNet152 V1 FPN 1024x1024 (RetinaNet152)','Faster R-CNN ResNet50 V1 640x640','Faster R-CNN ResNet50 V1 1024x1024','Faster R-CNN ResNet50 V1 800x1333','Faster R-CNN ResNet101 V1 640x640','Faster R-CNN ResNet101 V1 1024x1024','Faster R-CNN ResNet101 V1 800x1333','Faster R-CNN ResNet152 V1 640x640','Faster R-CNN ResNet152 V1 1024x1024','Faster R-CNN ResNet152 V1 800x1333','Faster R-CNN Inception ResNet V2 640x640','Faster R-CNN Inception ResNet V2 1024x1024','Mask R-CNN Inception ResNet V2 1024x1024']\n",
        "model_handle = ALL_MODELS[model_display_name]\n",
        "\n",
        "print('Selected model:'+ model_display_name)\n",
        "print('Model Handle at TensorFlow Hub: {}'.format(model_handle))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "muhUt-wWL582"
      },
      "source": [
        "## Loading the selected model from TensorFlow Hub\n",
        "\n",
        "Here we just need the model handle that was selected and use the Tensorflow Hub library to load it to memory.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rBuD07fLlcEO"
      },
      "outputs": [],
      "source": [
        "print('loading model...')\n",
        "hub_model = hub.load(model_handle)\n",
        "print('model loaded!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GIawRDKPPnd4"
      },
      "source": [
        "## Loading an image\n",
        "\n",
        "Let's try the model on a simple image. To help with this, we provide a list of test images.\n",
        "\n",
        "Here are some simple things to try out if you are curious:\n",
        "* Try running inference on your own images, just upload them to colab and load the same way it's done in the cell below.\n",
        "* Modify some of the input images and see if detection still works.  Some simple things to try out here include flipping the image horizontally, or converting to grayscale (note that we still expect the input image to have 3 channels).\n",
        "\n",
        "**Be careful:** when using images with an alpha channel, the model expect 3 channels images and the alpha will count as a 4th.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hX-AWUQ1wIEr"
      },
      "outputs": [],
      "source": [
        "#@title Image Selection (don't forget to execute the cell!) { display-mode: \"form\"}\n",
        "selected_image = 'Beach' # @param ['Beach', 'Dogs', 'Naxos Taverna', 'Beatles', 'Phones', 'Birds']\n",
        "flip_image_horizontally = False #@param {type:\"boolean\"}\n",
        "convert_image_to_grayscale = False #@param {type:\"boolean\"}\n",
        "\n",
        "image_path = IMAGES_FOR_TEST[selected_image]\n",
        "image_np = load_image_into_numpy_array(image_path)\n",
        "\n",
        "# Flip horizontally\n",
        "if(flip_image_horizontally):\n",
        "  image_np[0] = np.fliplr(image_np[0]).copy()\n",
        "\n",
        "# Convert image to grayscale\n",
        "if(convert_image_to_grayscale):\n",
        "  image_np[0] = np.tile(\n",
        "    np.mean(image_np[0], 2, keepdims=True), (1, 1, 3)).astype(np.uint8)\n",
        "\n",
        "plt.figure(figsize=(24,32))\n",
        "plt.imshow(image_np[0])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FTHsFjR6HNwb"
      },
      "source": [
        "## Doing the inference\n",
        "\n",
        "To do the inference we just need to call our TF Hub loaded model.\n",
        "\n",
        "Things you can try:\n",
        "* Print out `result['detection_boxes']` and try to match the box locations to the boxes in the image.  Notice that coordinates are given in normalized form (i.e., in the interval [0, 1]).\n",
        "* inspect other output keys present in the result. A full documentation can be seen on the models documentation page (pointing your browser to the model handle printed earlier)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gb_siXKcnnGC"
      },
      "outputs": [],
      "source": [
        "# running inference\n",
        "results = hub_model(image_np)\n",
        "\n",
        "# different object detection models have additional results\n",
        "# all of them are explained in the documentation\n",
        "result = {key:value.numpy() for key,value in results.items()}\n",
        "print(result.keys())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IZ5VYaBoeeFM"
      },
      "source": [
        "## Visualizing the results\n",
        "\n",
        "Here is where we will need the TensorFlow Object Detection API to show the squares from the inference step (and the keypoints when available).\n",
        "\n",
        "the full documentation of this method can be seen [here](https://github.com/tensorflow/models/blob/master/research/object_detection/utils/visualization_utils.py)\n",
        "\n",
        "Here you can, for example, set `min_score_thresh` to other values (between 0 and 1) to allow more detections in or to filter out more detections."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2O7rV8g9s8Bz"
      },
      "outputs": [],
      "source": [
        "label_id_offset = 0\n",
        "image_np_with_detections = image_np.copy()\n",
        "\n",
        "# Use keypoints if available in detections\n",
        "keypoints, keypoint_scores = None, None\n",
        "if 'detection_keypoints' in result:\n",
        "  keypoints = result['detection_keypoints'][0]\n",
        "  keypoint_scores = result['detection_keypoint_scores'][0]\n",
        "\n",
        "viz_utils.visualize_boxes_and_labels_on_image_array(\n",
        "      image_np_with_detections[0],\n",
        "      result['detection_boxes'][0],\n",
        "      (result['detection_classes'][0] + label_id_offset).astype(int),\n",
        "      result['detection_scores'][0],\n",
        "      category_index,\n",
        "      use_normalized_coordinates=True,\n",
        "      max_boxes_to_draw=200,\n",
        "      min_score_thresh=.30,\n",
        "      agnostic_mode=False,\n",
        "      keypoints=keypoints,\n",
        "      keypoint_scores=keypoint_scores,\n",
        "      keypoint_edges=COCO17_HUMAN_POSE_KEYPOINTS)\n",
        "\n",
        "plt.figure(figsize=(24,32))\n",
        "plt.imshow(image_np_with_detections[0])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qaw6Xi08NpEP"
      },
      "source": [
        "## [Optional]\n",
        "\n",
        "Among the available object detection models there's Mask R-CNN and the output of this model allows instance segmentation.\n",
        "\n",
        "To visualize it we will use the same method we did before but adding an aditional parameter: `instance_masks=output_dict.get('detection_masks_reframed', None)`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zl3qdtR1OvM_"
      },
      "outputs": [],
      "source": [
        "# Handle models with masks:\n",
        "image_np_with_mask = image_np.copy()\n",
        "\n",
        "if 'detection_masks' in result:\n",
        "  # we need to convert np.arrays to tensors\n",
        "  detection_masks = tf.convert_to_tensor(result['detection_masks'][0])\n",
        "  detection_boxes = tf.convert_to_tensor(result['detection_boxes'][0])\n",
        "\n",
        "  # Reframe the bbox mask to the image size.\n",
        "  detection_masks_reframed = utils_ops.reframe_box_masks_to_image_masks(\n",
        "            detection_masks, detection_boxes,\n",
        "              image_np.shape[1], image_np.shape[2])\n",
        "  detection_masks_reframed = tf.cast(detection_masks_reframed > 0.5,\n",
        "                                      tf.uint8)\n",
        "  result['detection_masks_reframed'] = detection_masks_reframed.numpy()\n",
        "\n",
        "viz_utils.visualize_boxes_and_labels_on_image_array(\n",
        "      image_np_with_mask[0],\n",
        "      result['detection_boxes'][0],\n",
        "      (result['detection_classes'][0] + label_id_offset).astype(int),\n",
        "      result['detection_scores'][0],\n",
        "      category_index,\n",
        "      use_normalized_coordinates=True,\n",
        "      max_boxes_to_draw=200,\n",
        "      min_score_thresh=.30,\n",
        "      agnostic_mode=False,\n",
        "      instance_masks=result.get('detection_masks_reframed', None),\n",
        "      line_thickness=8)\n",
        "\n",
        "plt.figure(figsize=(24,32))\n",
        "plt.imshow(image_np_with_mask[0])\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "「Object Detection Inference on TF 2 and TF Hub」的副本",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}